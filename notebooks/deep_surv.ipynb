{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pysurvival\n",
    "from pysurvival.models.simulations import SimulationModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper \n",
    "import torch # For building the networks \n",
    "import torchtuples as tt # Some useful functions\n",
    "from torch import nn\n",
    "\n",
    "from pycox.datasets import metabric\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from stg import STG,meter\n",
    "import stg.utils as stg_utils\n",
    "from stg.utils import SimpleDataset,FastTensorDataLoader,as_numpy,as_tensor\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from DeepSurv.deepsurv import deep_surv,utils,viz\n",
    "from DeepSurv.deepsurv.deepsurv_logger import DeepSurvLogger, TensorboardLogger\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lasagne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")\n",
    "\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../auton-survival/')\n",
    "\n",
    "from auton_survival import DeepCoxPH\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#datasets = utils.load_cox_gaussian_data()\n",
    "\n",
    "def minmax_scale(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df)\n",
    "    return scaler.transform(df)\n",
    "\n",
    "\n",
    "def minmax_stand_dfs(train_data,test_data,val_data):\n",
    "    \n",
    "    features = list(train_data.columns)\n",
    "    features.remove(\"time\")\n",
    "    features.remove(\"event\")\n",
    "    \n",
    "    train_data[features] = minmax_scale(train_data[features])\n",
    "    test_data[features] = minmax_scale(test_data[features])\n",
    "    val_data[features] = minmax_scale(val_data[features])\n",
    "    \n",
    "    return train_data,test_data,val_data\n",
    "    \n",
    "    \n",
    "\n",
    "def dataframe_to_datadicts(df, event_col = 'event', time_col = 'time'):\n",
    "    # Extract the event and time columns as numpy arrays\n",
    "    e = df[event_col].values.astype(np.int32)\n",
    "    t = df[time_col].values.astype(np.float32)\n",
    "\n",
    "    # Extract the patient's covariates as a numpy array\n",
    "    x_df = df.drop([event_col, time_col], axis = 1)\n",
    "    x = x_df.values.astype(np.float32)\n",
    "    \n",
    "    # Return the deep surv dataframe\n",
    "    return {\n",
    "        'x' : x,\n",
    "        'e' : e,\n",
    "        't' : t\n",
    "    }\n",
    "\n",
    "def prepare_stg_dataset(train_dict,valid_dict,test_dict):\n",
    "    \n",
    "    train_X = train_dict['x']\n",
    "    train_y = {'e': train_dict['e'], 't': train_dict['t']}\n",
    "    valid_X = valid_dict['x']\n",
    "    valid_y = {'e': valid_dict['e'], 't': valid_dict['t']}\n",
    "    test_X = test_dict['x']\n",
    "    test_y = {'e': test_dict['e'], 't': test_dict['t']}\n",
    "\n",
    "    train_dict={}\n",
    "    train_dict['X'], train_dict['E'], train_dict['T'] = stg_utils.prepare_data(train_X, train_y)\n",
    "    train_dict['ties'] = 'noties'\n",
    "\n",
    "    valid_dict={}\n",
    "    valid_dict['X'], valid_dict['E'], valid_dict['T'] = stg_utils.prepare_data(valid_X, valid_y)\n",
    "    valid_dict['ties'] = 'noties'\n",
    "\n",
    "    test_dict = {}\n",
    "    test_dict['X'], test_dict['E'], test_dict['T'] = stg_utils.prepare_data(test_X, test_y)\n",
    "    test_dict['ties'] = 'noties'\n",
    "    \n",
    "    return train_dict,test_dict,valid_dict\n",
    "\n",
    "\n",
    "def make_prediction_stg(stg_dict, stg_model):\n",
    "\n",
    "    data_loader = FastTensorDataLoader(torch.from_numpy(stg_dict[\"X\"]).float().to(stg_model.device), \n",
    "                        tensor_names=('X'), shuffle=False)\n",
    "    res = []\n",
    "    stg_model._model.eval()\n",
    "    for feed_dict in data_loader:\n",
    "        feed_dict_np = as_numpy(feed_dict)\n",
    "        feed_dict = as_tensor(feed_dict)\n",
    "        with torch.no_grad():\n",
    "            output_dict = stg_model._model(feed_dict)\n",
    "            output_dict_np = as_numpy(output_dict)\n",
    "            res.append(output_dict_np['logits'])\n",
    "    return np.concatenate(res, axis=0)\n",
    "\n",
    "def evaluate_sklearn_methods(train_data,test_data,sklearn_estimator,data_model_name):\n",
    "    X_train = train_data.drop([\"time\",\"event\"],axis=1).values\n",
    "    X_test = test_data.drop([\"time\",\"event\"],axis=1).values\n",
    "    \n",
    "    y_train_pred = sklearn_estimator.predict(X_train)\n",
    "    y_test_pred = sklearn_estimator.predict(X_test)\n",
    "    \n",
    "    conc_train = concordance_index_censored(train_data[\"event\"].astype(bool).values,\n",
    "                                           train_data[\"time\"].values,y_train_pred)[0]\n",
    "    conc_test = concordance_index_censored(test_data[\"event\"].astype(bool).values,\n",
    "                                           test_data[\"time\"].values,y_test_pred)[0]\n",
    "    \n",
    "    sklearn_metrics = pd.DataFrame({\n",
    "                                (conc_train,\n",
    "                                 conc_test\n",
    "                                 )}\n",
    "                                 ,columns=[\"train_conc\",\"test_conc\"],index=[data_model_name])\n",
    "    return sklearn_metrics\n",
    "    \n",
    "\n",
    "def evaluate_stg_model(stg_train_data, stg_val_data,stg_test_data,stg_model,data_set_name):\n",
    "    \n",
    "    train_pred_stg = make_prediction_stg(stg_train_data,stg_model)\n",
    "    val_pred_stg = make_prediction_stg(stg_val_data,stg_model)\n",
    "    test_pred_stg = make_prediction_stg(stg_test_data,stg_model)\n",
    "\n",
    "    con_ind_train = concordance_index_censored(stg_train_data[\"E\"].astype(bool),stg_train_data[\"T\"].astype(bool),\n",
    "                                           train_pred_stg.ravel())[0]\n",
    "    con_ind_test = concordance_index_censored(stg_test_data[\"E\"].astype(bool),stg_test_data[\"T\"].astype(bool),\n",
    "                                           test_pred_stg.ravel())[0]\n",
    "    con_ind_val = concordance_index_censored(stg_val_data[\"E\"].astype(bool),stg_val_data[\"T\"].astype(bool),\n",
    "                                           val_pred_stg.ravel())[0]\n",
    "\n",
    "    stg_metrics = pd.DataFrame({\n",
    "                                (con_ind_train,\n",
    "                                 con_ind_val,\n",
    "                                 con_ind_test)}\n",
    "                                 ,columns=[\"train_conc\",\"val_con\",\"test_conc\"],index=[data_set_name])\n",
    "    return stg_metrics\n",
    "\n",
    "\n",
    "def evaluate_ds_model(train_dict,val_dict,test_dict,ds_model,data_set_name):\n",
    "    y_pred_train_ds = ds_model.predict_risk(train_dict[\"x\"])\n",
    "    y_pred_val_ds = ds_model.predict_risk(val_dict[\"x\"])\n",
    "    y_pred_test_ds = ds_model.predict_risk(test_dict[\"x\"])\n",
    "\n",
    "    con_ind_train = concordance_index_censored(train_dict[\"e\"].astype(bool),train_dict[\"t\"].astype(bool),\n",
    "                                           y_pred_train_ds.ravel())[0]\n",
    "    con_ind_test = concordance_index_censored(test_dict[\"e\"].astype(bool),test_dict[\"t\"].astype(bool),\n",
    "                                           y_pred_test_ds.ravel())[0]\n",
    "    con_ind_val = concordance_index_censored(val_dict[\"e\"].astype(bool),val_dict[\"t\"].astype(bool),\n",
    "                                           y_pred_val_ds.ravel())[0]\n",
    "\n",
    "    ds_metrics = pd.DataFrame({\n",
    "                                (con_ind_train,\n",
    "                                 con_ind_val,\n",
    "                                 con_ind_test)}\n",
    "                                 ,columns=[\"train_conc\",\"val_con\",\"test_conc\"],index=[data_set_name])\n",
    "    return ds_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Number of data-points: 5000 - Number of events: 280.0\n",
      "Number of data-points: 1000 - Number of events: 55.0\n",
      "Number of data-points: 1000 - Number of events: 57.0\n",
      "Number of data-points: 5000 - Number of events: 534.0\n",
      "Number of data-points: 1000 - Number of events: 114.0\n",
      "Number of data-points: 1000 - Number of events: 116.0\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "# Initializing the simulation model\n",
    "lin_sim = SimulationModel(survival_distribution = 'exponential',\n",
    "                       risk_type = 'linear',\n",
    "                       censored_parameter = 1.0,\n",
    "                       alpha = 0.01,\n",
    "                       beta = 5., )\n",
    "\n",
    "gau_sim = SimulationModel(survival_distribution = 'exponential',\n",
    "                       risk_type = 'gaussian',\n",
    "                       censored_parameter = 7.0,\n",
    "                       alpha = 0.01,\n",
    "                       beta = 5., )\n",
    "\n",
    "# Generating N Random samples\n",
    "N = 5000\n",
    "linear_data_train=lin_sim.generate_data(num_samples = N, num_features=2).astype(float32)\n",
    "linear_data_test=lin_sim.generate_data(num_samples = int(0.2*N), num_features=2).astype(float32)\n",
    "linear_data_val=lin_sim.generate_data(num_samples = int(0.2*N), num_features=2).astype(float32)\n",
    "\n",
    "gaussian_data_train = gau_sim.generate_data(num_samples = N, num_features=2)\n",
    "gaussian_data_test = gau_sim.generate_data(num_samples = int(0.2*N), num_features=2)\n",
    "gaussian_data_val = gau_sim.generate_data(num_samples = int(0.2*N), num_features=2)\n",
    "\n",
    "linear_data_train,linear_data_test,linear_data_val =  minmax_stand_dfs(linear_data_train,linear_data_test,linear_data_val)\n",
    "gaussian_data_train,gaussian_data_test,gaussian_data_val = minmax_stand_dfs(gaussian_data_train,gaussian_data_test,gaussian_data_val)\n",
    "\n",
    "lin_train_dict = dataframe_to_datadicts(linear_data_train)\n",
    "lin_test_dict = dataframe_to_datadicts(linear_data_test)\n",
    "lin_val_dict = dataframe_to_datadicts(linear_data_val)\n",
    "\n",
    "gau_train_dict = dataframe_to_datadicts(gaussian_data_train)\n",
    "gau_test_dict = dataframe_to_datadicts(gaussian_data_test)\n",
    "gau_val_dict = dataframe_to_datadicts(gaussian_data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stg_train_lin,stg_test_lin,stg_val_lin = prepare_stg_dataset(lin_train_dict,lin_test_dict,lin_val_dict)\n",
    "stg_train_gau,stg_test_gau,stg_val_gau = prepare_stg_dataset(gau_train_dict,gau_test_dict,gau_val_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines With Sklearn Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_train_lin = pd.concat([linear_data_train,linear_data_val]).copy()\n",
    "sklearn_test_lin = linear_data_test.copy()\n",
    "\n",
    "X_lin = sklearn_train_lin.drop([\"time\",\"event\"],axis=1).values\n",
    "y_lin = np.array(sklearn_train_lin[[\"event\",\"time\"]].apply(tuple,axis=1).values,\n",
    "             dtype=[('Status', '?'), ('Survival_in_days', '<f8')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_conc</th>\n",
       "      <th>test_conc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cox_lin</th>\n",
       "      <td>0.845814</td>\n",
       "      <td>0.819414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_conc  test_conc\n",
       "cox_lin    0.845814   0.819414"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cox_est = CoxPHSurvivalAnalysis().fit(X_lin,y_lin)\n",
    "evaluate_sklearn_methods(sklearn_train_lin,sklearn_test_lin,cox_est,\"cox_lin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_conc</th>\n",
       "      <th>test_conc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rf_lin</th>\n",
       "      <td>0.981426</td>\n",
       "      <td>0.793979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train_conc  test_conc\n",
       "rf_lin    0.981426   0.793979"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_estimator = RandomSurvivalForest().fit(X_lin,y_lin)\n",
    "evaluate_sklearn_methods(sklearn_train_lin,sklearn_test_lin,rf_estimator,\"rf_lin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_train_gau = pd.concat([gaussian_data_train,gaussian_data_val]).copy()\n",
    "sklearn_test_gau = gaussian_data_val.copy()\n",
    "\n",
    "X_gau = sklearn_train_gau.drop([\"time\",\"event\"],axis=1).values\n",
    "y_gau = np.array(sklearn_train_gau[[\"event\",\"time\"]].apply(tuple,axis=1).values,\n",
    "             dtype=[('Status', '?'), ('Survival_in_days', '<f8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_conc</th>\n",
       "      <th>test_conc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cox_gau</th>\n",
       "      <td>0.515443</td>\n",
       "      <td>0.502828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_conc  test_conc\n",
       "cox_gau    0.515443   0.502828"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cox_est_gau = CoxPHSurvivalAnalysis().fit(X_gau,y_gau)\n",
    "evaluate_sklearn_methods(sklearn_train_gau,sklearn_test_gau,cox_est_gau,\"cox_gau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_conc</th>\n",
       "      <th>test_conc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rf_gau</th>\n",
       "      <td>0.935838</td>\n",
       "      <td>0.966817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train_conc  test_conc\n",
       "rf_gau    0.935838   0.966817"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_estimator_gau = RandomSurvivalForest().fit(X_gau,y_gau)\n",
    "evaluate_sklearn_methods(sklearn_train_gau,sklearn_test_gau,rf_estimator_gau,\"rf_gau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STG on Linear Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100: CI=0.832527 loss=8.246545 valid_CI=0.829125 valid_loss=5.348845\n",
      "Epoch: 200: CI=0.796939 loss=8.028740 valid_CI=0.815529 valid_loss=5.098709\n",
      "Passed time: 4.390125036239624\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" \n",
    "feature_selection = True\n",
    "\n",
    "lin_stg_model = STG(task_type='cox',input_dim=stg_train_lin['X'].shape[1], output_dim=1, hidden_dims=[25, 25], activation='selu',\n",
    "    optimizer='Adam', learning_rate=1e-03, batch_size=stg_train_lin['X'].shape[0], feature_selection=feature_selection, \n",
    "    sigma=0.5, lam=0.004, random_state=1, device=device)\n",
    "\n",
    "now = time.time()\n",
    "lin_stg_model.fit(stg_train_lin['X'], {'E': stg_train_lin['E'], 'T': stg_train_lin['T']}, nr_epochs=200, \n",
    "        valid_X=stg_val_lin['X'], valid_y={'E': stg_val_lin['E'], 'T': stg_val_lin['T']}, print_interval=100)\n",
    "print(\"Passed time: {}\".format(time.time() - now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_conc</th>\n",
       "      <th>val_con</th>\n",
       "      <th>test_conc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stg_lin</th>\n",
       "      <td>0.839897</td>\n",
       "      <td>0.810805</td>\n",
       "      <td>0.831281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_conc   val_con  test_conc\n",
       "stg_lin    0.839897  0.810805   0.831281"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_stg_metrics = evaluate_stg_model(stg_train_lin,stg_val_lin,stg_test_lin,lin_stg_model,\"stg_lin\")\n",
    "lin_stg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STGCoxModel(\n",
       "  (mlp): Sequential(\n",
       "    (0): LinearLayer(\n",
       "      (0): Linear(in_features=2, out_features=25, bias=True)\n",
       "      (1): SELU(inplace=True)\n",
       "    )\n",
       "    (1): LinearLayer(\n",
       "      (0): Linear(in_features=25, out_features=25, bias=True)\n",
       "      (1): SELU(inplace=True)\n",
       "    )\n",
       "    (2): Linear(in_features=25, out_features=1, bias=True)\n",
       "  )\n",
       "  (FeatureSelector): FeatureSelector()\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_stg_model._model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STG on Nonlinear Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100: CI=0.538677 loss=7.654104 valid_CI=0.504208 valid_loss=5.985466\n",
      "Epoch: 200: CI=0.547508 loss=7.654143 valid_CI=0.546263 valid_loss=5.985450\n",
      "Epoch: 300: CI=0.517855 loss=7.654148 valid_CI=0.505034 valid_loss=5.985452\n",
      "Passed time: 8.290906190872192\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" \n",
    "feature_selection = False \n",
    "\n",
    "gau_stg_model = STG(task_type='cox',input_dim=stg_train_gau['X'].shape[1], output_dim=1, hidden_dims=[25,25,5], activation='ReLU',\n",
    "    optimizer='Adam', learning_rate=1e-03, batch_size=stg_train_gau['X'].shape[0], feature_selection=feature_selection, \n",
    "    sigma=0.5, lam=10, random_state=1, device=device)\n",
    "\n",
    "now = time.time()\n",
    "gau_stg_model.fit(stg_train_gau['X'], {'E': stg_train_gau['E'], 'T': stg_train_gau['T']}, nr_epochs=300, \n",
    "        valid_X=stg_val_gau['X'], valid_y={'E': stg_val_gau['E'], 'T': stg_val_gau['T']}, print_interval=100)\n",
    "print(\"Passed time: {}\".format(time.time() - now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_conc</th>\n",
       "      <th>val_con</th>\n",
       "      <th>test_conc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gau_stg</th>\n",
       "      <td>0.511045</td>\n",
       "      <td>0.497562</td>\n",
       "      <td>0.509096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_conc   val_con  test_conc\n",
       "gau_stg    0.511045  0.497562   0.509096"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_stg_model(stg_train_gau,stg_val_gau,stg_test_gau,gau_stg_model,\"gau_stg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepSurv Model Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_surv_hyperparams_lin = {\n",
    "    'L2_reg': 10.0,\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.1,\n",
    "    'hidden_layers_sizes': [25, 25],\n",
    "    'learning_rate': 1e-03,\n",
    "    'lr_decay': 0.01,\n",
    "    'momentum': 0.1,\n",
    "    'n_in': lin_train_dict['x'].shape[1],\n",
    "    'standardize': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of DeepSurv using the hyperparams defined above\n",
    "ds_lin = deep_surv.DeepSurv(**deep_surv_hyperparams_lin)\n",
    "logger = None\n",
    "\n",
    "\n",
    "# Now we train the model\n",
    "update_fn=lasagne.updates.nesterov_momentum \n",
    "                                            \n",
    "n_epochs = 2000\n",
    "\n",
    "# If you have validation data, you can add it as the second parameter to the function\n",
    "lin_model_params = ds_lin.train(lin_train_dict,lin_val_dict, n_epochs=n_epochs, logger=logger, update_fn=update_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_conc</th>\n",
       "      <th>val_con</th>\n",
       "      <th>test_conc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ds_lin</th>\n",
       "      <td>0.819997</td>\n",
       "      <td>0.859606</td>\n",
       "      <td>0.831108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train_conc   val_con  test_conc\n",
       "ds_lin    0.819997  0.859606   0.831108"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_ds_model(lin_train_dict,lin_val_dict,lin_test_dict,ds_lin,\"ds_lin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Surv Model Nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_surv_hyperparams_gau = {\n",
    "    'L2_reg': 10.0,\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.1,\n",
    "    'hidden_layers_sizes': [25, 25],\n",
    "    'learning_rate': 1e-03,\n",
    "    'lr_decay': 0.01,\n",
    "    'momentum': 0.1,\n",
    "    'n_in': lin_train_dict['x'].shape[1],\n",
    "    'standardize': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of DeepSurv using the hyperparams defined above\n",
    "ds_gau = deep_surv.DeepSurv(**deep_surv_hyperparams_gau)\n",
    "logger = None\n",
    "\n",
    "\n",
    "# Now we train the model\n",
    "update_fn=lasagne.updates.nesterov_momentum \n",
    "                                            \n",
    "n_epochs = 2500\n",
    "\n",
    "# If you have validation data, you can add it as the second parameter to the function\n",
    "gau_model_params = ds_gau.train(gau_train_dict,gau_val_dict, n_epochs=n_epochs, logger=logger, update_fn=update_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_conc</th>\n",
       "      <th>val_con</th>\n",
       "      <th>test_conc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gau_lin</th>\n",
       "      <td>0.494497</td>\n",
       "      <td>0.477374</td>\n",
       "      <td>0.465217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_conc   val_con  test_conc\n",
       "gau_lin    0.494497  0.477374   0.465217"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_ds_model(gau_train_dict,gau_val_dict,gau_test_dict,ds_gau,\"gau_lin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auton CoxPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_train_dict[\"e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 296/500 [00:05<00:03, 51.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8142204743186235, 430217, 98162, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lincoxph = DeepCoxPH()\n",
    "lincoxph.fit(lin_train_dict[\"x\"], lin_train_dict[\"t\"], lin_train_dict[\"e\"],iters = 500)\n",
    "risk_preds = lincoxph.torch_model[0](torch.from_numpy(lin_train_dict[\"x\"]))\n",
    "risk_preds = risk_preds.detach().numpy()\n",
    "concordance_index_censored(lin_train_dict[\"e\"].astype(bool),lin_train_dict[\"t\"],risk_preds.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<00:00, 25.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5203551473820636, 913804, 842312, 0, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaucoxph = DeepCoxPH()\n",
    "gaucoxph.fit(gau_train_dict[\"x\"], gau_train_dict[\"t\"], gau_train_dict[\"e\"],iters = 10)\n",
    "risk_preds = gaucoxph.torch_model[0](torch.from_numpy(gau_train_dict[\"x\"]))\n",
    "risk_preds = risk_preds.detach().numpy()\n",
    "concordance_index_censored(gau_train_dict[\"e\"].astype(bool),gau_train_dict[\"t\"],risk_preds.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_torch.models.dnn_to_bnn import dnn_to_bnn, get_kl_loss\n",
    "const_bnn_prior_parameters = {\n",
    "        \"prior_mu\": 0.0,\n",
    "        \"prior_sigma\": 1.0,\n",
    "        \"posterior_mu_init\": 0.0,\n",
    "        \"posterior_rho_init\": -3.0,\n",
    "        \"type\": \"Reparameterization\",  # Flipout or Reparameterization\n",
    "        \"moped_enable\": False,  # True to initialize mu/sigma from the pretrained dnn weights\n",
    "        \"moped_delta\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_ll_loss(lrisks, tb, eb, eps=1e-3):\n",
    "\n",
    "    tb = tb + eps*np.random.random(len(tb))\n",
    "    sindex = np.argsort(-tb)\n",
    "\n",
    "    tb = tb[sindex]\n",
    "    eb = eb[sindex]\n",
    "\n",
    "    lrisks = lrisks[sindex]\n",
    "    lrisksdenom = torch.logcumsumexp(lrisks, dim = 0)\n",
    "\n",
    "    plls = lrisks - lrisksdenom\n",
    "    pll = plls[eb == 1]\n",
    "\n",
    "    pll = torch.sum(pll)\n",
    "\n",
    "    return -pll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 256\n",
    "learning_rate = 1e-3\n",
    "\n",
    "x = torch.from_numpy(lin_train_dict[\"x\"]).float()\n",
    "t = torch.from_numpy(lin_train_dict[\"t\"]).float()\n",
    "e = torch.from_numpy(lin_train_dict[\"e\"]).float()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPH_torch = lincoxph.torch_model[0]\n",
    "dnn_to_bnn(CPH_torch, const_bnn_prior_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(CPH_torch.parameters(), learning_rate)\n",
    "\n",
    "output = CPH_torch(xb)\n",
    "kl = get_kl_loss(CPH_torch)\n",
    "ce_loss = partial_ll_loss(output,tb,eb)\n",
    "loss = ce_loss + kl / batchsize\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_bnn_cph(cph_bnn, x, t, e, optimizer, batchsize=256):\n",
    "    \n",
    "    n = x.shape[0]\n",
    "\n",
    "    batches = (n // batchsize) + 1\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i in range(batches):\n",
    "\n",
    "        xb = x[i*batchsize:(i+1)*batchsize]\n",
    "        tb = t[i*batchsize:(i+1)*batchsize]\n",
    "        eb = e[i*batchsize:(i+1)*batchsize]\n",
    "\n",
    "        # Training Step\n",
    "\n",
    "        torch.enable_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = cph_bnn(xb)\n",
    "        kl = get_kl_loss(cph_bnn)\n",
    "        ce_loss = partial_ll_loss(output,tb,eb)\n",
    "        loss = ce_loss + kl / batchsize\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        epoch_loss += float(loss)\n",
    "    step_loss = epoch_loss/n\n",
    "    return step_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cph_bnn(cph_bnn, train_data, epochs=50,\n",
    "               patience=3, batchsize=256, lr=1e-3, debug=False,\n",
    "               random_state=0, return_losses=False):\n",
    "\n",
    "    torch.manual_seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    xt, tt, et = train_data\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    valc = np.inf\n",
    "    patience_ = 0\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        _ =train_step_bnn_cph(cph_bnn, xt, tt, et, optimizer, batchsize)\n",
    "        \n",
    "        #test_step_still has to be implemented\n",
    "        #valcn = test_step(model, xv, tv_, ev_)\n",
    "        valcn = _\n",
    "\n",
    "        losses.append(valcn)\n",
    "\n",
    "\n",
    "        if valcn > valc:\n",
    "            patience_ += 1\n",
    "        else:\n",
    "            patience_ = 0\n",
    "\n",
    "        if patience_ == patience:\n",
    "            break\n",
    "\n",
    "        valc = valcn\n",
    "\n",
    "    if return_losses:\n",
    "        return (model, breslow_spline), losses\n",
    "    else:\n",
    "        return (model, breslow_spline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 54.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch completed\n",
      "epoch completed\n",
      "epoch completed\n",
      "epoch completed\n",
      "epoch completed\n",
      "epoch completed\n",
      "epoch completed\n",
      "epoch completed\n",
      "epoch completed\n",
      "epoch completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(CPH_torch.parameters(), learning_rate)\n",
    "\n",
    "\n",
    "    n = x.shape[0]\n",
    "\n",
    "    batches = (n // batchsize) + 1\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i in range(batches):\n",
    "\n",
    "        xb = x[i*batchsize:(i+1)*batchsize]\n",
    "        tb = t[i*batchsize:(i+1)*batchsize]\n",
    "        eb = e[i*batchsize:(i+1)*batchsize]\n",
    "\n",
    "        # Training Step\n",
    "\n",
    "        torch.enable_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = CPH_torch(xb)\n",
    "        kl = get_kl_loss(CPH_torch)\n",
    "        ce_loss = partial_ll_loss(output,tb,eb)\n",
    "        loss = ce_loss + kl / batchsize\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        epoch_loss += float(loss)\n",
    "    step_loss = epoch_loss/n\n",
    "    print(\"epoch completed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BDNN_Zhang(nn.Module):\n",
    "  '''\n",
    "    DNN from the paper\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(4, 8),\n",
    "      nn.Tanh(),\n",
    "      nn.Linear(8, 4),\n",
    "      nn.Tanh(),\n",
    "      nn.Linear(4, 1),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Linear(1, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''\n",
    "      Forward pass\n",
    "    '''\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_torch_net(trainloader,neural_net,loss_function, n_epochs = 50):\n",
    "\n",
    "    optimizer = torch.optim.Adam(neural_net.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop\n",
    "    for epoch in range(0, n_epochs):  # 5 epochs at maximum\n",
    "\n",
    "        # Set current loss value\n",
    "        loss_per_batch = []\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # Get and prepare inputs\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.float(), targets.float()\n",
    "            #targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Perform forward pass\n",
    "            outputs = neural_net(inputs)\n",
    "            # Compute loss\n",
    "            loss = loss_function(outputs, targets)\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_per_batch.append(loss.item())\n",
    "\n",
    "    return neural_net, loss_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable_1</th>\n",
       "      <th>Variable_2</th>\n",
       "      <th>Variable_3</th>\n",
       "      <th>Variable_4</th>\n",
       "      <th>Event</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable_1   Variable_2  Variable_3  Variable_4  Event  Time\n",
       "0            0           3           2         4.6      1    43\n",
       "1            0           2           0         1.6      0    52\n",
       "2            0           3           0         3.5      1    73\n",
       "3            0           3           1         5.1      0    51\n",
       "4            0           2           0         1.7      0    51"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_fp = '../DeepSurv/notebooks/example_data.csv'\n",
    "train_df = pd.read_csv(train_dataset_fp)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_datasets = stg_utils.load_cox_gaussian_data()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}