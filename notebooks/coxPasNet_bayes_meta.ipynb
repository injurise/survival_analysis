{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoxPASNet.coxpasnet.DataLoader import load_data, load_pathway\n",
    "from CoxPASNet.coxpasnet.Train import trainCoxPASNet\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from CoxPASNet.coxpasnet.Survival_CostFunc_CIndex import R_set, neg_par_log_likelihood, c_index\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from bayesian_torch.models.dnn_to_bnn import dnn_to_bnn, get_kl_loss\n",
    "\n",
    "from run_pipeline.bayesian_custom_nn import run_custom_bnn,arguments\n",
    "from run_pipeline.cpath_bnn import run_cpath_bnn,arguments\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from src.data_prep.torch_datasets import cpath_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "''' Net Settings'''\n",
    "In_Nodes = 5567 ###number of genes\n",
    "Pathway_Nodes = 860 ###number of pathways\n",
    "Hidden_Nodes = 100 ###number of hidden nodes\n",
    "Out_Nodes = 30 ###number of hidden nodes in the last hidden layer\n",
    "''' Initialize '''\n",
    "Initial_Learning_Rate = [0.03] #[0.03, 0.01, 0.001, 0.00075]\n",
    "L2_Lambda = [0.01]  #[0.1, 0.01, 0.005, 0.001]\n",
    "num_epochs = 10 #3000 ###for grid search\n",
    "Num_EPOCHS = 15 #20000 ###for training\n",
    "###sub-network setup\n",
    "Dropout_Rate = [0.7,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' load data and pathway '''\n",
    "pathway_mask = load_pathway(\"../data/pathway_mask.csv\", dtype)\n",
    "\n",
    "x_train, ytime_train, yevent_train, age_train = load_data(\"../data/train.csv\", dtype)\n",
    "x_valid, ytime_valid, yevent_valid, age_valid = load_data(\"../data/validation.csv\", dtype)\n",
    "x_test, ytime_test, yevent_test, age_test = load_data(\"../data/test.csv\", dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathway_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_mask = pd.read_csv(\"../data/pathway_mask.csv\", index_col=0).values\n",
    "pat_mask = torch.from_numpy(pat_mask).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dy/sjxgt5r91_s5m71lvl0gghh80000gn/T/ipykernel_31724/1022548363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_np\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "X_train_np,tb = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in Train:  tensor([4.7949], grad_fn=<ViewBackward0>)\n",
      "L2:  0.01 LR:  0.03 Loss in Validation:  tensor([3.4735], grad_fn=<ViewBackward0>)\n",
      "Loss in Train:  tensor([4.7948], grad_fn=<ViewBackward0>)\n",
      "Optimal L2:  0.01 Optimal LR:  0.03\n",
      "C-index in Test:  tensor(0.6699)\n"
     ]
    }
   ],
   "source": [
    "opt_l2_loss = 0\n",
    "opt_lr_loss = 0\n",
    "opt_loss = torch.Tensor([float(\"Inf\")])\n",
    "###if gpu is being used\n",
    "if torch.cuda.is_available():\n",
    "\topt_loss = opt_loss.cuda()\n",
    "###\n",
    "opt_c_index_va = 0\n",
    "opt_c_index_tr = 0\n",
    "###grid search the optimal hyperparameters using train and validation data\n",
    "for l2 in L2_Lambda:\n",
    "\tfor lr in Initial_Learning_Rate:\n",
    "\t\tloss_train, loss_valid, c_index_tr, c_index_va = trainCoxPASNet(x_train, age_train, ytime_train, yevent_train, \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tx_valid, age_valid, ytime_valid, yevent_valid, pathway_mask, \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tIn_Nodes, Pathway_Nodes, Hidden_Nodes, Out_Nodes, \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlr, l2, num_epochs, Dropout_Rate)\n",
    "\t\tif loss_valid < opt_loss:\n",
    "\t\t\topt_l2_loss = l2\n",
    "\t\t\topt_lr_loss = lr\n",
    "\t\t\topt_loss = loss_valid\n",
    "\t\t\topt_c_index_tr = c_index_tr\n",
    "\t\t\topt_c_index_va = c_index_va\n",
    "\t\tprint (\"L2: \", l2, \"LR: \", lr, \"Loss in Validation: \", loss_valid)\n",
    "\n",
    "\n",
    "\n",
    "###train Cox-PASNet with optimal hyperparameters using train data, and then evaluate the trained model with test data\n",
    "###Note that test data are only used to evaluate the trained Cox-PASNet\n",
    "loss_train, loss_test, c_index_tr, c_index_te = trainCoxPASNet(x_train, age_train, ytime_train, yevent_train, \\\n",
    "\t\t\t\t\t\t\tx_test, age_test, ytime_test, yevent_test, pathway_mask, \\\n",
    "\t\t\t\t\t\t\tIn_Nodes, Pathway_Nodes, Hidden_Nodes, Out_Nodes, \\\n",
    "\t\t\t\t\t\t\topt_lr_loss, opt_l2_loss, Num_EPOCHS, Dropout_Rate)\n",
    "print (\"Optimal L2: \", opt_l2_loss, \"Optimal LR: \", opt_lr_loss)\n",
    "print(\"C-index in Test: \", c_index_te)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cox_PASNet(nn.Module):\n",
    "\tdef __init__(self, In_Nodes, Pathway_Nodes, Hidden_Nodes, Out_Nodes, Pathway_Mask):\n",
    "\t\tsuper(Cox_PASNet, self).__init__()\n",
    "\t\tself.tanh = nn.Tanh()\n",
    "\t\tself.pathway_mask = Pathway_Mask\n",
    "\t\t###gene layer --> pathway layer\n",
    "\t\tself.sc1 = nn.Linear(In_Nodes, Pathway_Nodes)\n",
    "\t\t###pathway layer --> hidden layer\n",
    "\t\tself.sc2 = nn.Linear(Pathway_Nodes, Hidden_Nodes)\n",
    "\t\t###hidden layer --> hidden layer 2\n",
    "\t\tself.sc3 = nn.Linear(Hidden_Nodes, Out_Nodes, bias=False)\n",
    "\t\t###hidden layer 2 + age --> Cox layer\n",
    "\t\tself.sc4 = nn.Linear(Out_Nodes+1, 1, bias = False)\n",
    "\t\tself.sc4.weight.data.uniform_(-0.001, 0.001)\n",
    "\t\t###randomly select a small sub-network\n",
    "\t\tself.do_m1 = torch.ones(Pathway_Nodes)\n",
    "\t\tself.do_m2 = torch.ones(Hidden_Nodes)\n",
    "\t\t###if gpu is being used\n",
    "\t\tif torch.cuda.is_available():\n",
    "\t\t\tself.do_m1 = self.do_m1.cuda()\n",
    "\t\t\tself.do_m2 = self.do_m2.cuda()\n",
    "\t\t###\n",
    "\n",
    "\tdef forward(self, x_1, x_2):\n",
    "\t\t###force the connections between gene layer and pathway layer w.r.t. 'pathway_mask'\n",
    "\t\tself.sc1.weight.data = self.sc1.weight.data.mul(self.pathway_mask)\n",
    "\t\tx_1 = self.tanh(self.sc1(x_1))\n",
    "\t\tif self.training == True: ###construct a small sub-network for training only\n",
    "\t\t\tx_1 = x_1.mul(self.do_m1)\n",
    "\t\tx_1 = self.tanh(self.sc2(x_1))\n",
    "\t\tif self.training == True: ###construct a small sub-network for training only\n",
    "\t\t\tx_1 = x_1.mul(self.do_m2)\n",
    "\t\tx_1 = self.tanh(self.sc3(x_1))\n",
    "\t\t###combine age with hidden layer 2\n",
    "\t\tx_cat = torch.cat((x_1, x_2), 1)\n",
    "\t\tlin_pred = self.sc4(x_cat)\n",
    "\t\t\n",
    "\t\treturn lin_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make scripts so that they work with the age variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bay_CPathNet(nn.Module):\n",
    "\n",
    "    def __init__(self, In_Nodes, Hidden_Nodes,Last_Nodes, mean=0., variance=0.1):\n",
    "        super(Bay_CPathNet, self).__init__()\n",
    "        # self.tanh = nn.Tanh()\n",
    "        self.l1 = LinearReparam(in_features=In_Nodes,\n",
    "                                    out_features=Hidden_Nodes,\n",
    "                                    prior_means=np.full((Hidden_Nodes, In_Nodes), mean),\n",
    "                                    prior_variances=np.full((Hidden_Nodes, In_Nodes), variance),\n",
    "                                    posterior_mu_init=np.full((Hidden_Nodes, In_Nodes), 0.5),\n",
    "                                    posterior_rho_init=np.full((Hidden_Nodes, In_Nodes), -3.),\n",
    "                                    bias=False,\n",
    "                                    )\n",
    "        \n",
    "        self.l2 = LinearReparam(in_features=Hidden_Nodes,\n",
    "                                    out_features=Hidden_Nodes,\n",
    "                                    prior_means=np.full((Hidden_Nodes,Hidden_Nodes),mean),\n",
    "                                    prior_variances=np.full((Hidden_Nodes,Hidden_Nodes),variance),\n",
    "                                    posterior_mu_init=np.full((Hidden_Nodes, Hidden_Nodes), 0.5),\n",
    "                                    posterior_rho_init=np.full((Hidden_Nodes, Hidden_Nodes), -3.),\n",
    "                                    bias=False,\n",
    "                                    )\n",
    "        \n",
    "        \n",
    "        self.l3 = LinearReparam(in_features=Hidden_Nodes,\n",
    "                                    out_features=Last_Nodes,\n",
    "                                    prior_means=np.full((Last_Nodes,Hidden_Nodes),mean),\n",
    "                                    prior_variances=np.full((Last_Nodes,Hidden_Nodes),variance),\n",
    "                                    posterior_mu_init=np.full((Last_Nodes, Hidden_Nodes), 0.5),\n",
    "                                    posterior_rho_init=np.full((Last_Nodes, Hidden_Nodes), -3.),\n",
    "                                    bias=False,\n",
    "                                    )\n",
    "\n",
    "\n",
    "        self.l4 = LinearReparam(in_features=Last_Nodes+1,\n",
    "                                    out_features=1,\n",
    "                                    prior_means=np.full((1, Last_Nodes+1), mean),\n",
    "                                    prior_variances=np.full((1, Last_Nodes+1), variance),\n",
    "                                    posterior_mu_init=np.full((1, Last_Nodes+1), 0.5),\n",
    "                                    posterior_rho_init=np.full((1, Last_Nodes+1), -3.),\n",
    "                                    bias=False,\n",
    "                                    )\n",
    "\n",
    "\n",
    "    def forward(self, x, clinical_vars):\n",
    "            pred = nn.Tanh(self.l1.forward(x))\n",
    "            pred = nn.Tanh(self.l2(pred,return_kl = False))\n",
    "            pred = nn.Tanh(self.l3(pred,return_kl = False))\n",
    "            x_cat = torch.cat((x_1, clinical_vars), 1)\n",
    "            lin_pred = self.l4(x_cat,return_kl = False)\n",
    "\n",
    "            return lin_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/train.csv\")\n",
    "X_train_np =  train_data.drop([\"SAMPLE_ID\", \"OS_MONTHS\", \"OS_EVENT\", \"AGE\"], axis = 1).values\n",
    "tb_train = train_data.loc[:, [\"OS_MONTHS\"]].values\n",
    "e_train = train_data.loc[:, [\"OS_EVENT\"]].values\n",
    "clinical_vars_train = train_data.loc[:, [\"AGE\"]].values\n",
    "\n",
    "val_data = pd.read_csv(\"../data/validation.csv\")\n",
    "X_val_np =  val_data.drop([\"SAMPLE_ID\", \"OS_MONTHS\", \"OS_EVENT\", \"AGE\"], axis = 1).values\n",
    "tb_val = val_data.loc[:, [\"OS_MONTHS\"]].values\n",
    "e_val = val_data.loc[:, [\"OS_EVENT\"]].values\n",
    "clinical_vars_val = val_data.loc[:, [\"AGE\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpath_train_dataset = cpath_dataset(X_train_np,\n",
    "                                    clinical_vars_train,\n",
    "                                    tb_train,\n",
    "                                    e_train)\n",
    "\n",
    "cpath_val_dataset = cpath_dataset(X_val_np,\n",
    "                                  clinical_vars_val,\n",
    "                                  tb_val,\n",
    "                                  e_val)\n",
    "\n",
    "    #run model\n",
    "\n",
    "#args = arguments(200, 84, 50, 10, \"train\", 0.01, 0, \"test_model_cpath\", \"model_checkpoints\")\n",
    "\n",
    "#model = Bay_CPathNet(5567, 100, 30,variance = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = torch.from_numpy(X_train_np)\n",
    "tes = tes.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosPas_BNN_NJ(nn.Module):\n",
    "        def __init__(self, In_Nodes, Hidden_Nodes,Last_Nodes):\n",
    "            super(CosPas_BNN_NJ, self).__init__()\n",
    "            # activation\n",
    "            self.tanh = nn.Tanh()\n",
    "            # layers\n",
    "            self.fc1 = LinearGroupNJ(In_Nodes, Hidden_Nodes, clip_var=0.04, cuda=BNN_NJ_Flags.cuda)\n",
    "            self.fc2 = LinearGroupNJ(Hidden_Nodes, Hidden_Nodes, cuda=BNN_NJ_Flags.cuda)\n",
    "            self.fc3 = LinearGroupNJ(Hidden_Nodes, Hidden_Nodes, cuda=BNN_NJ_Flags.cuda)\n",
    "            self.fc4 = LinearGroupNJ(Hidden_Nodes+1, 1, cuda=BNN_NJ_Flags.cuda)\n",
    "            # layers including kl_divergence\n",
    "            self.kl_list = [self.fc1, self.fc2, self.fc3,self.fc4]\n",
    "\n",
    "        def forward(self, x,clinical_vars):\n",
    "            x = self.tanh(self.fc1(x))\n",
    "            x = self.tanh(self.fc2(x))\n",
    "            x = self.tanh(self.fc3(x))\n",
    "            x_cat = torch.cat((x, clinical_vars), 1)\n",
    "            lin_pred = self.fc4(x_cat)\n",
    "            \n",
    "            return lin_pred\n",
    "\n",
    "        def get_masks(self,thresholds):\n",
    "            weight_masks = []\n",
    "            mask = None\n",
    "            for i, (layer, threshold) in enumerate(zip(self.kl_list, thresholds)):\n",
    "                # compute dropout mask\n",
    "                if mask is None:\n",
    "                    log_alpha = layer.get_log_dropout_rates().cpu().data.numpy()\n",
    "                    mask = log_alpha < threshold\n",
    "                else:\n",
    "                    mask = np.copy(next_mask)\n",
    "                try:\n",
    "                    log_alpha = layers[i + 1].get_log_dropout_rates().cpu().data.numpy()\n",
    "                    next_mask = log_alpha < thresholds[i + 1]\n",
    "                except:\n",
    "                    # must be the last mask\n",
    "                    next_mask = np.ones(10)\n",
    "\n",
    "                weight_mask = np.expand_dims(mask, axis=0) * np.expand_dims(next_mask, axis=1)\n",
    "                weight_masks.append(weight_mask.astype(np.float))\n",
    "            return weight_masks\n",
    "\n",
    "        def kl_divergence(self):\n",
    "            KLD = 0\n",
    "            for layer in self.kl_list:\n",
    "                KLD += layer.kl_divergence()\n",
    "            return KLD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_ll_loss(lrisks, tb, eb, eps=1e-3):\n",
    "\n",
    "    tb = tb + eps*np.random.random(len(tb))\n",
    "    sindex = np.argsort(-tb)\n",
    "\n",
    "    tb = tb[sindex]\n",
    "    eb = eb[sindex]\n",
    "\n",
    "    lrisks = lrisks[sindex]\n",
    "    lrisksdenom = torch.logcumsumexp(lrisks, dim = 0)\n",
    "\n",
    "    plls = lrisks - lrisksdenom\n",
    "    pll = plls[eb == 1]\n",
    "\n",
    "    pll = torch.sum(pll)\n",
    "\n",
    "    return -pll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN_NJ_Flags_class():\n",
    "        def __init__(self, num_mc,epochs,batch_size,print_freq,thresholds,cuda = False):\n",
    "            self.num_mc = num_mc\n",
    "            self.epochs = epochs\n",
    "            self.batch_size = batch_size\n",
    "            self.print_freq = print_freq\n",
    "            self.thresholds = thresholds\n",
    "            self.cuda = cuda\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "BNN_NJ_Flags= BNN_NJ_Flags_class(200,10,84,2,[-2.8, -3., -5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/train.csv\")\n",
    "X_train_np = train_data.drop([\"SAMPLE_ID\", \"OS_MONTHS\", \"OS_EVENT\", \"AGE\"], axis=1).values\n",
    "tb_train = train_data.loc[:, [\"OS_MONTHS\"]].values\n",
    "e_train = train_data.loc[:, [\"OS_EVENT\"]].values\n",
    "clinical_vars_train = train_data.loc[:, [\"AGE\"]].values\n",
    "\n",
    "val_data = pd.read_csv(\"../data/validation.csv\")\n",
    "X_val_np = val_data.drop([\"SAMPLE_ID\", \"OS_MONTHS\", \"OS_EVENT\", \"AGE\"], axis=1).values\n",
    "tb_val = val_data.loc[:, [\"OS_MONTHS\"]].values\n",
    "e_val = val_data.loc[:, [\"OS_EVENT\"]].values\n",
    "clinical_vars_val = val_data.loc[:, [\"AGE\"]].values\n",
    "\n",
    "cpath_train_dataset = cpath_dataset(X_train_np,\n",
    "                                        clinical_vars_train,\n",
    "                                        tb_train,\n",
    "                                        e_train)\n",
    "\n",
    "cpath_val_dataset = cpath_dataset(X_val_np,\n",
    "                                      clinical_vars_val,\n",
    "                                      tb_val,\n",
    "                                      e_val)\n",
    "\n",
    "    # import data\n",
    "cpath_train_loader = torch.utils.data.DataLoader(cpath_train_dataset,\n",
    "                                            batch_size=50,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=0)\n",
    "\n",
    "cpath_val_loader = torch.utils.data.DataLoader(cpath_val_dataset,\n",
    "                                            batch_size=40,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cpath_val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/train.csv\")\n",
    "X_train_np = train_data.drop([\"SAMPLE_ID\", \"OS_MONTHS\", \"OS_EVENT\", \"AGE\"], axis=1).values\n",
    "tb_train = train_data.loc[:, [\"OS_MONTHS\"]].values\n",
    "e_train = train_data.loc[:, [\"OS_EVENT\"]].values\n",
    "clinical_vars_train = train_data.loc[:, [\"AGE\"]].values\n",
    "\n",
    "val_data = pd.read_csv(\"../data/validation.csv\")\n",
    "X_val_np = val_data.drop([\"SAMPLE_ID\", \"OS_MONTHS\", \"OS_EVENT\", \"AGE\"], axis=1).values\n",
    "tb_val = val_data.loc[:, [\"OS_MONTHS\"]].values\n",
    "e_val = val_data.loc[:, [\"OS_EVENT\"]].values\n",
    "clinical_vars_val = val_data.loc[:, [\"AGE\"]].values\n",
    "\n",
    "cpath_train_dataset = cpath_dataset(X_train_np,\n",
    "                                        clinical_vars_train,\n",
    "                                        tb_train,\n",
    "                                        e_train)\n",
    "\n",
    "cpath_val_dataset = cpath_dataset(X_val_np,\n",
    "                                      clinical_vars_val,\n",
    "                                      tb_val,\n",
    "                                      e_val)\n",
    "\n",
    "    # import data\n",
    "cpath_train_loader = torch.utils.data.DataLoader(cpath_train_dataset,\n",
    "                                            batch_size=BNN_NJ_Flags.batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=0)\n",
    "\n",
    "cpath_val_loader = torch.utils.data.DataLoader(cpath_val_dataset,\n",
    "                                            batch_size=BNN_NJ_Flags.batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=0)\n",
    "\n",
    "\n",
    "    # for later analysis we take some sample digits\n",
    "    #mask = 255. * (np.ones((1, 28, 28)))\n",
    "    #examples = train_loader.sampler.data_source.train_data[0:5].numpy()\n",
    "    #images = np.vstack([mask, examples])\n",
    "\n",
    "    # build a simple MLP\n",
    "    \n",
    "    # init model\n",
    "model = CosPas_BNN_NJ(5567, 100, 30)\n",
    "if BNN_NJ_Flags.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "    # init optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # we optimize the variational lower bound scaled by the number of data\n",
    "    # points (so we can keep our intuitions about hyper-params such as the learning rate)\n",
    "\n",
    " \n",
    "\n",
    "def train(BNN_NJ_Flags,model,cpath_train_loader,epoch,optimizer):        \n",
    "        \n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        plls = AverageMeter()\n",
    "        c_indexs = AverageMeter()\n",
    "\n",
    "        # switch to train mode\n",
    "        model.train()\n",
    "\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(cpath_train_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            tb = target[\"tb\"].cpu()\n",
    "            e = target[\"e\"].cpu()\n",
    "            input_var = input[\"X\"].cpu()\n",
    "            clinical_var = input[\"clinical_vars\"].cpu()\n",
    "            \n",
    "            output_ = []\n",
    "            for mc_run in range(BNN_NJ_Flags.num_mc):\n",
    "                output = model(input_var,clinical_var)\n",
    "                output_.append(output)\n",
    "            output = torch.mean(torch.stack(output_), dim=0)\n",
    "            loss_crit_metric = partial_ll_loss(output.reshape(-1),tb.reshape(-1),e.reshape(-1))\n",
    "            scaled_loss_crit_metric = loss_crit_metric / BNN_NJ_Flags.batch_size\n",
    "            scaled_kl = model.kl_divergence() / BNN_NJ_Flags.batch_size\n",
    "            loss =  loss_crit_metric + scaled_kl\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            for layer in model.kl_list:\n",
    "                    layer.clip_variances()\n",
    "                \n",
    "            conc_metric = concordance_index_censored(e.detach().numpy().astype(bool).reshape(-1),\n",
    "                                                     tb.detach().numpy().reshape(-1),\n",
    "                                                     output.reshape(-1).detach().numpy())[0]\n",
    "            output = output.float()\n",
    "            loss = loss.float()\n",
    "            # measure accuracy and record loss\n",
    "            losses.update(loss.item(), input[\"X\"].size(0))\n",
    "            plls.update(scaled_loss_crit_metric.item(), input[\"X\"].size(0))\n",
    "            c_indexs.update(conc_metric, input[\"X\"].size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % BNN_NJ_Flags.print_freq == 0:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'PLL {plls.val:.3f} ({plls.avg:.3f})\\t'\n",
    "                      'C-Index {c_ind.val:.3f} ({c_ind.avg:.3f})'.format(\n",
    "                          epoch,\n",
    "                          i,\n",
    "                          len(cpath_train_loader),\n",
    "                          batch_time=batch_time,\n",
    "                          data_time=data_time,\n",
    "                          loss=losses,\n",
    "                          plls=plls,\n",
    "                          c_ind=c_indexs))\n",
    "\n",
    "def test():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            if FLAGS.cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            output = model(data)\n",
    "            test_loss += discrimination_loss(output, target, size_average=False).data[0]\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('Test loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    # train the model and save some visualisations on the way\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_cpath_nj_model(args, cpath_val_loader, model, epoch, tb_writer=None):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    errors = AverageMeter()\n",
    "    c_indexs = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(cpath_val_loader):\n",
    "\n",
    "            tb = target[\"tb\"].cpu()\n",
    "            e = target[\"e\"].cpu()\n",
    "            input_var = input[\"X\"].cpu()\n",
    "            clinical_var = input[\"clinical_vars\"].cpu()\n",
    "\n",
    "            # compute output\n",
    "            output_ = []\n",
    "            for mc_run in range(args.num_mc):\n",
    "                output = model(input_var,clinical_var)\n",
    "                output_.append(output)\n",
    "            output = torch.mean(torch.stack(output_), dim=0)\n",
    "            error_metric = partial_ll_loss(output.reshape(-1), tb.reshape(-1), e.reshape(-1))\n",
    "            scaled_error_metric = error_metric /  args.batch_size\n",
    "            scaled_kl = model.kl_divergence() / args.batch_size\n",
    "\n",
    "            #ELBO loss\n",
    "            loss = error_metric + scaled_kl\n",
    "\n",
    "            conc_metric = concordance_index_censored(e.detach().numpy().astype(bool).reshape(-1),\n",
    "                                                     tb.detach().numpy().reshape(-1),\n",
    "                                                     output.reshape(-1).detach().numpy())[0]\n",
    "\n",
    "            output = output.float()\n",
    "            loss = loss.float()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            losses.update(loss.item(), input[\"X\"].size(0))\n",
    "            errors.update(scaled_error_metric.item(), input[\"X\"].size(0))\n",
    "            c_indexs.update(conc_metric,input[\"X\"].size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Error {error.val:.3f} ({error.avg:.3f})\\t'\n",
    "                      'C-Index {c_ind.val:.3f} ({c_ind.avg:.3f}) '.format(\n",
    "                          i,\n",
    "                          len(cpath_val_loader),\n",
    "                          batch_time=batch_time,\n",
    "                          loss=losses,\n",
    "                          error=errors,\n",
    "                          c_ind=c_indexs))\n",
    "       \n",
    "    print(' * Error {error.avg:.3f}'.format(error=errors))\n",
    "\n",
    "    return errors.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/4]\tTime 5.696 (5.696)\tData 0.009 (0.009)\tLoss 28061.5723 (28061.5723)\tPLL 2.946 (2.946)\tC-Index 0.666 (0.666)\n",
      "Epoch: [1][2/4]\tTime 5.598 (5.634)\tData 0.001 (0.004)\tLoss 28012.2598 (28038.8249)\tPLL 2.442 (2.717)\tC-Index 0.788 (0.717)\n",
      "Test: [0/1]\tTime 1.315 (1.315)\tLoss 28087.1992 (28087.1992)\tError 3.418 (3.418)\tC-Index 0.435 (0.435) \n",
      " * Error 3.418\n",
      "Epoch: [2][0/4]\tTime 5.787 (5.787)\tData 0.001 (0.001)\tLoss 28039.2676 (28039.2676)\tPLL 2.847 (2.847)\tC-Index 0.740 (0.740)\n",
      "Epoch: [2][2/4]\tTime 5.597 (5.682)\tData 0.001 (0.001)\tLoss 28007.4766 (28022.2253)\tPLL 2.552 (2.686)\tC-Index 0.781 (0.762)\n",
      "Test: [0/1]\tTime 1.317 (1.317)\tLoss 28070.6875 (28070.6875)\tError 3.388 (3.388)\tC-Index 0.483 (0.483) \n",
      " * Error 3.388\n",
      "Epoch: [3][0/4]\tTime 5.649 (5.649)\tData 0.001 (0.001)\tLoss 27992.9238 (27992.9238)\tPLL 2.462 (2.462)\tC-Index 0.857 (0.857)\n",
      "Epoch: [3][2/4]\tTime 5.617 (5.679)\tData 0.001 (0.001)\tLoss 28015.6621 (28001.8327)\tPLL 2.816 (2.610)\tC-Index 0.772 (0.814)\n",
      "Test: [0/1]\tTime 1.341 (1.341)\tLoss 28060.8809 (28060.8809)\tError 3.438 (3.438)\tC-Index 0.510 (0.510) \n",
      " * Error 3.438\n",
      "Epoch: [4][0/4]\tTime 5.856 (5.856)\tData 0.001 (0.001)\tLoss 27975.4180 (27975.4180)\tPLL 2.420 (2.420)\tC-Index 0.855 (0.855)\n",
      "Epoch: [4][2/4]\tTime 5.627 (5.722)\tData 0.001 (0.001)\tLoss 27955.1152 (27973.2812)\tPLL 2.262 (2.436)\tC-Index 0.857 (0.846)\n",
      "Test: [0/1]\tTime 1.326 (1.326)\tLoss 28053.9082 (28053.9082)\tError 3.521 (3.521)\tC-Index 0.531 (0.531) \n",
      " * Error 3.521\n",
      "Epoch: [5][0/4]\tTime 5.593 (5.593)\tData 0.001 (0.001)\tLoss 27951.2227 (27951.2227)\tPLL 2.299 (2.299)\tC-Index 0.883 (0.883)\n",
      "Epoch: [5][2/4]\tTime 5.643 (5.653)\tData 0.001 (0.001)\tLoss 27948.7852 (27945.4141)\tPLL 2.353 (2.271)\tC-Index 0.866 (0.878)\n",
      "Test: [0/1]\tTime 1.328 (1.328)\tLoss 28046.3066 (28046.3066)\tError 3.597 (3.597)\tC-Index 0.573 (0.573) \n",
      " * Error 3.597\n",
      "Epoch: [6][0/4]\tTime 5.609 (5.609)\tData 0.001 (0.001)\tLoss 27942.0117 (27942.0117)\tPLL 2.356 (2.356)\tC-Index 0.870 (0.870)\n",
      "Epoch: [6][2/4]\tTime 5.756 (5.843)\tData 0.002 (0.001)\tLoss 27910.2715 (27923.9258)\tPLL 2.061 (2.182)\tC-Index 0.911 (0.897)\n",
      "Test: [0/1]\tTime 1.330 (1.330)\tLoss 28045.1582 (28045.1582)\tError 3.750 (3.750)\tC-Index 0.552 (0.552) \n",
      " * Error 3.750\n",
      "Epoch: [7][0/4]\tTime 5.746 (5.746)\tData 0.001 (0.001)\tLoss 27912.5762 (27912.5762)\tPLL 2.172 (2.172)\tC-Index 0.903 (0.903)\n",
      "Epoch: [7][2/4]\tTime 5.853 (5.763)\tData 0.001 (0.001)\tLoss 27870.3242 (27896.6484)\tPLL 1.752 (2.024)\tC-Index 0.904 (0.912)\n",
      "Test: [0/1]\tTime 1.332 (1.332)\tLoss 28050.7070 (28050.7070)\tError 3.983 (3.983)\tC-Index 0.557 (0.557) \n",
      " * Error 3.983\n",
      "Epoch: [8][0/4]\tTime 5.628 (5.628)\tData 0.001 (0.001)\tLoss 27864.2168 (27864.2168)\tPLL 1.763 (1.763)\tC-Index 0.937 (0.937)\n",
      "Epoch: [8][2/4]\tTime 5.674 (5.660)\tData 0.001 (0.001)\tLoss 27873.7012 (27867.3086)\tPLL 1.959 (1.841)\tC-Index 0.935 (0.937)\n",
      "Test: [0/1]\tTime 1.369 (1.369)\tLoss 28043.8555 (28043.8555)\tError 4.068 (4.068)\tC-Index 0.588 (0.588) \n",
      " * Error 4.068\n",
      "Epoch: [9][0/4]\tTime 5.789 (5.789)\tData 0.001 (0.001)\tLoss 27844.7324 (27844.7324)\tPLL 1.697 (1.697)\tC-Index 0.936 (0.936)\n",
      "Epoch: [9][2/4]\tTime 5.678 (5.724)\tData 0.001 (0.001)\tLoss 27843.5371 (27843.7682)\tPLL 1.766 (1.727)\tC-Index 0.941 (0.940)\n",
      "Test: [0/1]\tTime 1.335 (1.335)\tLoss 28080.4082 (28080.4082)\tError 4.669 (4.669)\tC-Index 0.593 (0.593) \n",
      " * Error 4.669\n",
      "Epoch: [10][0/4]\tTime 5.838 (5.838)\tData 0.001 (0.001)\tLoss 27828.8125 (27828.8125)\tPLL 1.674 (1.674)\tC-Index 0.951 (0.951)\n",
      "Epoch: [10][2/4]\tTime 5.865 (5.836)\tData 0.001 (0.001)\tLoss 27829.8438 (27828.7708)\tPLL 1.769 (1.715)\tC-Index 0.951 (0.950)\n",
      "Test: [0/1]\tTime 1.348 (1.348)\tLoss 28081.2070 (28081.2070)\tError 4.845 (4.845)\tC-Index 0.573 (0.573) \n",
      " * Error 4.845\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, BNN_NJ_Flags.epochs + 1):\n",
    "    train(BNN_NJ_Flags,model,cpath_train_loader,epoch,optimizer)\n",
    "            #test()\n",
    "            # visualizations\n",
    "    val_score = validate_cpath_nj_model(BNN_NJ_Flags, cpath_val_loader, model, epoch)\n",
    "                             \n",
    "    weight_mus = [model.fc1.weight_mu, model.fc2.weight_mu]\n",
    "    log_alphas = [model.fc1.get_log_dropout_rates(), model.fc2.get_log_dropout_rates(),\n",
    "                          model.fc3.get_log_dropout_rates()]\n",
    "            #visualise_weights(weight_mus, log_alphas, epoch=epoch)\n",
    "            #log_alpha = model.fc1.get_log_dropout_rates().cpu().data.numpy()\n",
    "            #visualize_pixel_importance(images, log_alpha=log_alpha, epoch=str(epoch))\n",
    "\n",
    "            # compute compression rate and new model accuracy\n",
    "    layers = [model.fc1, model.fc2, model.fc3]\n",
    "#thresholds = FLAGS.thresholds\n",
    "#compute_compression_rate(layers, model.get_masks(thresholds))\n",
    "\n",
    "    #print(\"Test error after with reduced bit precision:\")\n",
    "\n",
    "    #weights = compute_reduced_weights(layers, model.get_masks(thresholds))\n",
    "    #for layer, weight in zip(layers, weights):\n",
    "     #   if FLAGS.cuda:\n",
    "      #      layer.post_weight_mu.data = torch.Tensor(weight).cuda()\n",
    "       # else:\n",
    "        #    layer.post_weight_mu.data = torch.Tensor(weight)\n",
    "    #for layer in layers: layer.deterministic = True\n",
    "    #test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.l1.forward(tes,return_kl = False).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-301.4059, -298.6887, -304.2516,  ..., -295.9987, -301.2021,\n",
       "         -300.9999],\n",
       "        [-840.2748, -849.6366, -844.2791,  ..., -834.6867, -840.2144,\n",
       "         -844.5341],\n",
       "        [ 743.9192,  739.9576,  732.7419,  ...,  748.3130,  747.7260,\n",
       "          735.9771],\n",
       "        ...,\n",
       "        [-265.4668, -263.0511, -258.8149,  ..., -266.2320, -262.6032,\n",
       "         -258.1574],\n",
       "        [ 951.9144,  952.3220,  944.4562,  ...,  932.3268,  941.6860,\n",
       "          954.7036],\n",
       "        [ 406.7895,  391.3521,  388.9161,  ...,  393.7029,  395.9680,\n",
       "          398.4599]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dy/sjxgt5r91_s5m71lvl0gghh80000gn/T/ipykernel_78944/2123956368.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "torch.nn.Tanh(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9640, 0.9951, 0.9993, 0.9999],\n",
       "        [0.9640, 0.9951, 1.0000, 0.9951]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.tensor([[2,3,4,5],[2,3,23,3]])\n",
    "v = torch.nn.Tanh()\n",
    "v(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current lr 1.00000e-02\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dy/sjxgt5r91_s5m71lvl0gghh80000gn/T/ipykernel_78682/2596701396.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_cpath_bnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpath_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpath_val_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#inp = torch.tensor([[0.5, 0.5]], dtype=torch.float)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/survival_analysis/run_pipeline/cpath_bnn.py\u001b[0m in \u001b[0;36mrun_cpath_bnn\u001b[0;34m(cpath_train_dataset, cpath_val_dataset, model, args, mode)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'current lr {:.5e}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             train_cpath_bnn(args, cpath_train_loader, model, optimizer, epoch,\n\u001b[0m\u001b[1;32m     47\u001b[0m               tb_writer)\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/survival_analysis/src/models/bnn_cust_cpath.py\u001b[0m in \u001b[0;36mtrain_cpath_bnn\u001b[0;34m(args, cpath_train_loader, model, optimizer, epoch, tb_writer)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mkl_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmc_run\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclinical_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0moutput_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mkl_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/survival_analysis/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/dy/sjxgt5r91_s5m71lvl0gghh80000gn/T/ipykernel_78682/3897867282.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, clinical_vars)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclinical_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "run_cpath_bnn(cpath_train_dataset,cpath_val_dataset,model,args,\"train\")\n",
    "\n",
    "\n",
    "\n",
    "    #inp = torch.tensor([[0.5, 0.5]], dtype=torch.float)\n",
    "\n",
    "    #print(model(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayesian_torch.layers as bayesian_layers\n",
    "from bayesian_torch.utils.util import get_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_layer = LinearReparam(\n",
    "        in_features=2,\n",
    "        out_features=1,\n",
    "        prior_means=np.array([[0.,0.]]),\n",
    "        prior_variances=np.array([[0.1,0.1]]),\n",
    "        posterior_mu_init=np.array([[0.,0.]]),\n",
    "        posterior_rho_init=np.array([[0.1,0.1]]),\n",
    "        bias=False,\n",
    "    )\n",
    "\n",
    "#test_layer.kl_loss()\n",
    "\n",
    "#inp = torch.tensor([[1]],dtype = torch.float)\n",
    "#r = test_layer.forward(inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_layer.mu_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.]])"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[0.,0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_layer.prior_weight_mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_lay_normal = LinearReparameterization(\n",
    "        in_features=3,\n",
    "        out_features=2,\n",
    "        prior_mean=0,\n",
    "        prior_variance=0.00000001,\n",
    "        posterior_mu_init=0.5,\n",
    "        posterior_rho_init=-3,\n",
    "        bias=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5124, 0.4482, 0.5500],\n",
       "        [0.6314, 0.5597, 0.4710]])"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lay_normal.mu_weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lay_normal.posterior_mu_init[0]\n",
    "test_lay_normal.mu_weight\n",
    "test_lay_normal.prior_weight_sigma\n",
    "test_lay_normal.prior_bias_mu\n",
    "test_lay_normal.prior_weight_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.1000], dtype=torch.float64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Tmr check why these layers dont yield the same result. Maybe assign some variables\n",
    "# and call get kl function to see if that one works\n",
    "\n",
    "test_layer.prior_bias_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inp = torch.tensor([[1]],dtype = torch.float)\n",
    "\n",
    "res_normal_1 = []\n",
    "res_normal_2 = []\n",
    "res_normal_kl = []\n",
    "res_new_1 = []\n",
    "res_new_2 = []\n",
    "res_new_kl = []\n",
    "\n",
    "for i in range(10000):\n",
    "    norm_res = test_lay_normal.forward(inp)\n",
    "    new_res = test_layer.forward(inp)\n",
    "\n",
    "    res_normal_1.append(norm_res[0].detach().numpy()[0][0])\n",
    "    res_normal_2.append(norm_res[0].detach().numpy()[0][1])\n",
    "    res_normal_kl.append(norm_res[1].detach().numpy())\n",
    "\n",
    "    res_new_1.append(new_res[0].detach().numpy()[0][0])\n",
    "    res_new_2.append(new_res[0].detach().numpy()[0][1])\n",
    "    res_new_kl.append(new_res[1].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0.],[0.]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Bay_TestNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, In_Nodes, Hidden_Nodes, Out_Nodes,mean=0.,variance=.1):\n",
    "        super(Bay_TestNet, self).__init__()\n",
    "        #self.tanh = nn.Tanh()\n",
    "        self.l1 = LinearReparam(in_features=In_Nodes,\n",
    "                                out_features=Out_Nodes,\n",
    "                                prior_means=np.array([[0.,3.5]]), #np.full((Out_Nodes,In_Nodes),mean)\n",
    "                                prior_variances= np.array([[0.1,0.5]]),#np.full((Out_Nodes,In_Nodes),variance)\n",
    "                                posterior_mu_init=np.array([[2.,0.5]]),\n",
    "                                posterior_rho_init=np.array([[-3.,-3.]]),\n",
    "                                bias=False,\n",
    "                                )\n",
    "        \n",
    "        '''\n",
    "        self.l2 = LinearReparam(in_features=Hidden_Nodes,\n",
    "                                out_features=Hidden_Nodes,\n",
    "                                prior_means=np.full((Hidden_Nodes,Hidden_Nodes),mean),\n",
    "                                prior_variances=np.full((Hidden_Nodes,Hidden_Nodes),variance),\n",
    "                                posterior_mu_init=0.5,\n",
    "                                posterior_rho_init=-3.0,\n",
    "                                bias=False,\n",
    "                                )\n",
    "        \n",
    "        self.l3 = LinearReparam(in_features=Hidden_Nodes,\n",
    "                                out_features=Hidden_Nodes,\n",
    "                                prior_means=np.full((Hidden_Nodes,Hidden_Nodes),mean),\n",
    "                                prior_variances=np.full((Hidden_Nodes,Hidden_Nodes),variance),\n",
    "                                posterior_mu_init=0.5,\n",
    "                                posterior_rho_init=-3.0,\n",
    "                                bias=False,\n",
    "                                )\n",
    "        self.l4 = LinearReparam(in_features=Hidden_Nodes,\n",
    "                                out_features=Out_Nodes,\n",
    "                                prior_means=np.full((Out_Nodes,Hidden_Nodes),mean),\n",
    "                                prior_variances=np.full((Out_Nodes,Hidden_Nodes),variance),\n",
    "                                posterior_mu_init=0.5,\n",
    "                                posterior_rho_init=-3.0,\n",
    "                                bias=False,\n",
    "                                )\n",
    "        '''\n",
    "    def forward(self, x):\n",
    "        \n",
    "        lin_pred = self.l1(x)\n",
    "\n",
    "        return lin_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y, scale_data=False):\n",
    "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "            if scale_data:\n",
    "                X = StandardScaler().fit_transform(X)\n",
    "            self.X = torch.from_numpy(X).float()\n",
    "            self.y = torch.from_numpy(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments():\n",
    "    def __init__(self,num_mc,batch_size,print_freq,epochs,mode,lr,workers,model_name,save_dir):\n",
    "        self.num_mc = num_mc\n",
    "        self.batch_size = batch_size\n",
    "        self.print_freq = print_freq\n",
    "        self.epochs = epochs\n",
    "        self.mode = mode\n",
    "        self.lr = lr\n",
    "        self.workers = workers\n",
    "        self.model_name = model_name\n",
    "        self.save_dir = save_dir\n",
    "        \n",
    "args = arguments(200,1,500,10,\"test\",0.00009,0,\"test_model_no_noise\",\"model_checkpoints\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current lr 1.00000e-02\n",
      "Epoch: [0][0/6]\tTime 0.064 (0.064)\tData 0.001 (0.001)\tLoss 19.8398 (19.8398)\tMses 0.207 (0.207)\n",
      "Epoch: [0][5/6]\tTime 0.041 (0.045)\tData 0.000 (0.000)\tLoss 19.3413 (19.4961)\tMses 0.700 (0.361)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 18.7888 (18.7888)\tError0.341 (0.341)\n",
      " * Error 0.411\n",
      "current lr 1.00000e-02\n",
      "Epoch: [1][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 18.7847 (18.7847)\tMses 0.337 (0.337)\n",
      "Epoch: [1][5/6]\tTime 0.042 (0.038)\tData 0.000 (0.000)\tLoss 18.2065 (18.3227)\tMses 0.721 (0.358)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 17.6394 (17.6394)\tError0.342 (0.342)\n",
      " * Error 0.408\n",
      "current lr 1.00000e-02\n",
      "Epoch: [2][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 17.7836 (17.7836)\tMses 0.486 (0.486)\n",
      "Epoch: [2][5/6]\tTime 0.046 (0.042)\tData 0.000 (0.000)\tLoss 17.5481 (17.1908)\tMses 1.180 (0.360)\n",
      "Test: [0/2]\tTime 0.016 (0.016)\tLoss 16.5211 (16.5211)\tError0.332 (0.332)\n",
      " * Error 0.414\n",
      "current lr 1.00000e-02\n",
      "Epoch: [3][0/6]\tTime 0.043 (0.043)\tData 0.000 (0.000)\tLoss 16.9041 (16.9041)\tMses 0.715 (0.715)\n",
      "Epoch: [3][5/6]\tTime 0.044 (0.044)\tData 0.000 (0.000)\tLoss 15.6861 (16.0993)\tMses 0.391 (0.359)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 15.4729 (15.4729)\tError0.353 (0.353)\n",
      " * Error 0.423\n",
      "current lr 1.00000e-02\n",
      "Epoch: [4][0/6]\tTime 0.042 (0.042)\tData 0.000 (0.000)\tLoss 16.0959 (16.0959)\tMses 0.976 (0.976)\n",
      "Epoch: [4][5/6]\tTime 0.045 (0.045)\tData 0.000 (0.000)\tLoss 14.3776 (15.0555)\tMses 0.123 (0.370)\n",
      "Test: [0/2]\tTime 0.016 (0.016)\tLoss 14.4395 (14.4395)\tError0.354 (0.354)\n",
      " * Error 0.428\n",
      "current lr 1.00000e-02\n",
      "Epoch: [5][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 14.4033 (14.4033)\tMses 0.318 (0.318)\n",
      "Epoch: [5][5/6]\tTime 0.039 (0.041)\tData 0.000 (0.000)\tLoss 13.5589 (14.0410)\tMses 0.305 (0.374)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 13.4393 (13.4393)\tError0.349 (0.349)\n",
      " * Error 0.427\n",
      "current lr 1.00000e-02\n",
      "Epoch: [6][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 13.9883 (13.9883)\tMses 0.898 (0.898)\n",
      "Epoch: [6][5/6]\tTime 0.041 (0.040)\tData 0.000 (0.000)\tLoss 12.4250 (13.0704)\tMses 0.130 (0.379)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 12.5034 (12.5034)\tError0.366 (0.366)\n",
      " * Error 0.447\n",
      "current lr 1.00000e-02\n",
      "Epoch: [7][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 12.9768 (12.9768)\tMses 0.839 (0.839)\n",
      "Epoch: [7][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 11.8364 (12.1414)\tMses 0.468 (0.390)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 11.5984 (11.5984)\tError0.381 (0.381)\n",
      " * Error 0.457\n",
      "current lr 1.00000e-02\n",
      "Epoch: [8][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 11.6455 (11.6455)\tMses 0.428 (0.428)\n",
      "Epoch: [8][5/6]\tTime 0.048 (0.050)\tData 0.000 (0.000)\tLoss 10.6820 (11.2424)\tMses 0.197 (0.393)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 10.7225 (10.7225)\tError0.382 (0.382)\n",
      " * Error 0.462\n",
      "current lr 1.00000e-02\n",
      "Epoch: [9][0/6]\tTime 0.040 (0.040)\tData 0.000 (0.000)\tLoss 11.6776 (11.6776)\tMses 1.337 (1.337)\n",
      "Epoch: [9][5/6]\tTime 0.039 (0.043)\tData 0.000 (0.000)\tLoss 10.0667 (10.3932)\tMses 0.431 (0.408)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 9.9037 (9.9037)\tError0.406 (0.406)\n",
      " * Error 0.473\n",
      "current lr 1.00000e-02\n",
      "Epoch: [10][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 9.6057 (9.6057)\tMses 0.108 (0.108)\n",
      "Epoch: [10][5/6]\tTime 0.045 (0.039)\tData 0.000 (0.000)\tLoss 8.9576 (9.5601)\tMses 0.136 (0.403)\n",
      "Test: [0/2]\tTime 0.016 (0.016)\tLoss 9.0733 (9.0733)\tError0.383 (0.383)\n",
      " * Error 0.465\n",
      "current lr 1.00000e-02\n",
      "Epoch: [11][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 9.1878 (9.1878)\tMses 0.497 (0.497)\n",
      "Epoch: [11][5/6]\tTime 0.039 (0.043)\tData 0.000 (0.000)\tLoss 9.0115 (8.7818)\tMses 0.970 (0.418)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 8.3115 (8.3115)\tError0.395 (0.395)\n",
      " * Error 0.483\n",
      "current lr 1.00000e-02\n",
      "Epoch: [12][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 8.5209 (8.5209)\tMses 0.605 (0.605)\n",
      "Epoch: [12][5/6]\tTime 0.041 (0.040)\tData 0.000 (0.000)\tLoss 7.8516 (8.0259)\tMses 0.546 (0.417)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 7.5759 (7.5759)\tError0.389 (0.389)\n",
      " * Error 0.480\n",
      "current lr 1.00000e-02\n",
      "Epoch: [13][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 7.4591 (7.4591)\tMses 0.273 (0.273)\n",
      "Epoch: [13][5/6]\tTime 0.046 (0.043)\tData 0.000 (0.000)\tLoss 6.9381 (7.3215)\tMses 0.336 (0.429)\n",
      "Test: [0/2]\tTime 0.016 (0.016)\tLoss 6.8910 (6.8910)\tError0.403 (0.403)\n",
      " * Error 0.480\n",
      "current lr 1.00000e-02\n",
      "Epoch: [14][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 6.7903 (6.7903)\tMses 0.302 (0.302)\n",
      "Epoch: [14][5/6]\tTime 0.042 (0.040)\tData 0.000 (0.000)\tLoss 6.2770 (6.6479)\tMses 0.335 (0.436)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 6.2602 (6.2602)\tError0.423 (0.423)\n",
      " * Error 0.504\n",
      "current lr 1.00000e-02\n",
      "Epoch: [15][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 6.3643 (6.3643)\tMses 0.527 (0.527)\n",
      "Epoch: [15][5/6]\tTime 0.043 (0.049)\tData 0.000 (0.000)\tLoss 6.2798 (6.0028)\tMses 0.966 (0.429)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 5.6341 (5.6341)\tError0.420 (0.420)\n",
      " * Error 0.504\n",
      "current lr 1.00000e-02\n",
      "Epoch: [16][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 5.3646 (5.3646)\tMses 0.150 (0.150)\n",
      "Epoch: [16][5/6]\tTime 0.042 (0.039)\tData 0.000 (0.000)\tLoss 5.2036 (5.4122)\tMses 0.465 (0.438)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 5.0701 (5.0701)\tError0.425 (0.425)\n",
      " * Error 0.511\n",
      "current lr 1.00000e-02\n",
      "Epoch: [17][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 4.9117 (4.9117)\tMses 0.266 (0.266)\n",
      "Epoch: [17][5/6]\tTime 0.047 (0.041)\tData 0.000 (0.000)\tLoss 4.3439 (4.8445)\tMses 0.158 (0.432)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 4.5114 (4.5114)\tError0.412 (0.412)\n",
      " * Error 0.515\n",
      "current lr 1.00000e-02\n",
      "Epoch: [18][0/6]\tTime 0.042 (0.042)\tData 0.000 (0.000)\tLoss 4.4089 (4.4089)\tMses 0.310 (0.310)\n",
      "Epoch: [18][5/6]\tTime 0.044 (0.045)\tData 0.000 (0.000)\tLoss 3.8932 (4.3223)\tMses 0.221 (0.439)\n",
      "Test: [0/2]\tTime 0.016 (0.016)\tLoss 4.0249 (4.0249)\tError0.434 (0.434)\n",
      " * Error 0.520\n",
      "current lr 1.00000e-02\n",
      "Epoch: [19][0/6]\tTime 0.042 (0.042)\tData 0.000 (0.000)\tLoss 3.7292 (3.7292)\tMses 0.138 (0.138)\n",
      "Epoch: [19][5/6]\tTime 0.041 (0.043)\tData 0.000 (0.000)\tLoss 3.7939 (3.8398)\tMses 0.593 (0.447)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 3.5519 (3.5519)\tError0.425 (0.425)\n",
      " * Error 0.518\n",
      "current lr 1.00000e-02\n",
      "Epoch: [20][0/6]\tTime 0.043 (0.043)\tData 0.000 (0.000)\tLoss 3.3063 (3.3063)\tMses 0.180 (0.180)\n",
      "Epoch: [20][5/6]\tTime 0.041 (0.044)\tData 0.000 (0.000)\tLoss 3.6826 (3.3746)\tMses 0.924 (0.435)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 3.1335 (3.1335)\tError0.443 (0.443)\n",
      " * Error 0.536\n",
      "current lr 1.00000e-02\n",
      "Epoch: [21][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 3.0782 (3.0782)\tMses 0.388 (0.388)\n",
      "Epoch: [21][5/6]\tTime 0.049 (0.040)\tData 0.000 (0.000)\tLoss 2.4750 (2.9775)\tMses 0.116 (0.456)\n",
      "Test: [0/2]\tTime 0.017 (0.017)\tLoss 2.7156 (2.7156)\tError0.419 (0.419)\n",
      " * Error 0.525\n",
      "current lr 1.00000e-02\n",
      "Epoch: [22][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 3.4084 (3.4084)\tMses 1.111 (1.111)\n",
      "Epoch: [22][5/6]\tTime 0.045 (0.044)\tData 0.000 (0.000)\tLoss 2.3700 (2.6055)\tMses 0.368 (0.458)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 2.3499 (2.3499)\tError0.405 (0.405)\n",
      " * Error 0.530\n",
      "current lr 1.00000e-02\n",
      "Epoch: [23][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 2.2668 (2.2668)\tMses 0.322 (0.322)\n",
      "Epoch: [23][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 3.0452 (2.2448)\tMses 1.377 (0.440)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 2.0569 (2.0569)\tError0.435 (0.435)\n",
      " * Error 0.540\n",
      "current lr 1.00000e-02\n",
      "Epoch: [24][0/6]\tTime 0.042 (0.042)\tData 0.000 (0.000)\tLoss 1.8381 (1.8381)\tMses 0.217 (0.217)\n",
      "Epoch: [24][5/6]\tTime 0.043 (0.043)\tData 0.000 (0.000)\tLoss 1.6657 (1.9502)\tMses 0.282 (0.452)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 1.7770 (1.7770)\tError0.435 (0.435)\n",
      " * Error 0.518\n",
      "current lr 1.00000e-02\n",
      "Epoch: [25][0/6]\tTime 0.040 (0.040)\tData 0.000 (0.000)\tLoss 1.8562 (1.8562)\tMses 0.514 (0.514)\n",
      "Epoch: [25][5/6]\tTime 0.044 (0.042)\tData 0.000 (0.000)\tLoss 1.5886 (1.6852)\tMses 0.448 (0.448)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 1.5446 (1.5446)\tError0.441 (0.441)\n",
      " * Error 0.519\n",
      "current lr 1.00000e-02\n",
      "Epoch: [26][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 1.4959 (1.4959)\tMses 0.393 (0.393)\n",
      "Epoch: [26][5/6]\tTime 0.045 (0.043)\tData 0.000 (0.000)\tLoss 1.3240 (1.4754)\tMses 0.392 (0.461)\n",
      "Test: [0/2]\tTime 0.016 (0.016)\tLoss 1.3565 (1.3565)\tError0.456 (0.456)\n",
      " * Error 0.541\n",
      "current lr 1.00000e-02\n",
      "Epoch: [27][0/6]\tTime 0.040 (0.040)\tData 0.000 (0.000)\tLoss 1.3769 (1.3769)\tMses 0.476 (0.476)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [27][5/6]\tTime 0.044 (0.044)\tData 0.000 (0.000)\tLoss 1.6780 (1.2808)\tMses 0.931 (0.460)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 1.1575 (1.1575)\tError0.432 (0.432)\n",
      " * Error 0.503\n",
      "current lr 1.00000e-02\n",
      "Epoch: [28][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 0.8125 (0.8125)\tMses 0.087 (0.087)\n",
      "Epoch: [28][5/6]\tTime 0.045 (0.044)\tData 0.000 (0.000)\tLoss 1.3473 (1.1164)\tMses 0.730 (0.451)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 1.0166 (1.0166)\tError0.413 (0.413)\n",
      " * Error 0.493\n",
      "current lr 1.00000e-02\n",
      "Epoch: [29][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 1.6027 (1.6027)\tMses 0.999 (0.999)\n",
      "Epoch: [29][5/6]\tTime 0.040 (0.041)\tData 0.000 (0.000)\tLoss 1.1015 (1.0013)\tMses 0.540 (0.408)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.8946 (0.8946)\tError0.347 (0.347)\n",
      " * Error 0.446\n",
      "current lr 1.00000e-02\n",
      "Epoch: [30][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 1.8254 (1.8254)\tMses 1.278 (1.278)\n",
      "Epoch: [30][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 1.0195 (0.9265)\tMses 0.489 (0.378)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.8115 (0.8115)\tError0.292 (0.292)\n",
      " * Error 0.366\n",
      "current lr 1.00000e-02\n",
      "Epoch: [31][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.6517 (0.6517)\tMses 0.132 (0.132)\n",
      "Epoch: [31][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.5554 (0.8068)\tMses 0.107 (0.327)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.7318 (0.7318)\tError0.293 (0.293)\n",
      " * Error 0.350\n",
      "current lr 1.00000e-02\n",
      "Epoch: [32][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 0.7681 (0.7681)\tMses 0.329 (0.329)\n",
      "Epoch: [32][5/6]\tTime 0.039 (0.041)\tData 0.000 (0.000)\tLoss 1.0721 (0.6966)\tMses 0.690 (0.286)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.6251 (0.6251)\tError0.249 (0.249)\n",
      " * Error 0.319\n",
      "current lr 1.00000e-02\n",
      "Epoch: [33][0/6]\tTime 0.039 (0.039)\tData 0.000 (0.000)\tLoss 0.4288 (0.4288)\tMses 0.053 (0.053)\n",
      "Epoch: [33][5/6]\tTime 0.043 (0.043)\tData 0.000 (0.000)\tLoss 0.5832 (0.6130)\tMses 0.236 (0.255)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.5298 (0.5298)\tError0.187 (0.187)\n",
      " * Error 0.245\n",
      "current lr 1.00000e-02\n",
      "Epoch: [34][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.4645 (0.4645)\tMses 0.122 (0.122)\n",
      "Epoch: [34][5/6]\tTime 0.045 (0.039)\tData 0.000 (0.000)\tLoss 0.5294 (0.5275)\tMses 0.233 (0.213)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.4522 (0.4522)\tError0.158 (0.158)\n",
      " * Error 0.199\n",
      "current lr 1.00000e-02\n",
      "Epoch: [35][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 0.7401 (0.7401)\tMses 0.445 (0.445)\n",
      "Epoch: [35][5/6]\tTime 0.041 (0.042)\tData 0.000 (0.000)\tLoss 0.3931 (0.4686)\tMses 0.102 (0.173)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.4188 (0.4188)\tError0.132 (0.132)\n",
      " * Error 0.162\n",
      "current lr 1.00000e-02\n",
      "Epoch: [36][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 0.4424 (0.4424)\tMses 0.156 (0.156)\n",
      "Epoch: [36][5/6]\tTime 0.046 (0.043)\tData 0.000 (0.000)\tLoss 0.3046 (0.4060)\tMses 0.039 (0.131)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.3641 (0.3641)\tError0.104 (0.104)\n",
      " * Error 0.127\n",
      "current lr 1.00000e-02\n",
      "Epoch: [37][0/6]\tTime 0.043 (0.043)\tData 0.000 (0.000)\tLoss 0.3472 (0.3472)\tMses 0.087 (0.087)\n",
      "Epoch: [37][5/6]\tTime 0.042 (0.044)\tData 0.000 (0.000)\tLoss 0.2829 (0.3371)\tMses 0.064 (0.101)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.3001 (0.3001)\tError0.084 (0.084)\n",
      " * Error 0.093\n",
      "current lr 1.00000e-02\n",
      "Epoch: [38][0/6]\tTime 0.040 (0.040)\tData 0.000 (0.000)\tLoss 0.2441 (0.2441)\tMses 0.028 (0.028)\n",
      "Epoch: [38][5/6]\tTime 0.039 (0.042)\tData 0.000 (0.000)\tLoss 0.2699 (0.2774)\tMses 0.081 (0.078)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.2442 (0.2442)\tError0.058 (0.058)\n",
      " * Error 0.075\n",
      "current lr 1.00000e-02\n",
      "Epoch: [39][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.2203 (0.2203)\tMses 0.034 (0.034)\n",
      "Epoch: [39][5/6]\tTime 0.046 (0.040)\tData 0.000 (0.000)\tLoss 0.2775 (0.2317)\tMses 0.105 (0.054)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.1942 (0.1942)\tError0.023 (0.023)\n",
      " * Error 0.032\n",
      "current lr 1.00000e-02\n",
      "Epoch: [40][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 0.2674 (0.2674)\tMses 0.097 (0.097)\n",
      "Epoch: [40][5/6]\tTime 0.039 (0.040)\tData 0.000 (0.000)\tLoss 0.1715 (0.1951)\tMses 0.017 (0.030)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.1683 (0.1683)\tError0.019 (0.019)\n",
      " * Error 0.023\n",
      "current lr 1.00000e-02\n",
      "Epoch: [41][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.1649 (0.1649)\tMses 0.016 (0.016)\n",
      "Epoch: [41][5/6]\tTime 0.044 (0.042)\tData 0.000 (0.000)\tLoss 0.1275 (0.1518)\tMses 0.002 (0.016)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.1310 (0.1310)\tError0.008 (0.008)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-02\n",
      "Epoch: [42][0/6]\tTime 0.040 (0.040)\tData 0.000 (0.000)\tLoss 0.1277 (0.1277)\tMses 0.005 (0.005)\n",
      "Epoch: [42][5/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 0.1092 (0.1208)\tMses 0.000 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.1072 (0.1072)\tError0.001 (0.001)\n",
      " * Error 0.001\n",
      "current lr 1.00000e-02\n",
      "Epoch: [43][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 0.1063 (0.1063)\tMses 0.000 (0.000)\n",
      "Epoch: [43][5/6]\tTime 0.042 (0.043)\tData 0.000 (0.000)\tLoss 0.0894 (0.0987)\tMses 0.000 (0.002)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0869 (0.0869)\tError0.000 (0.000)\n",
      " * Error 0.000\n",
      "current lr 1.00000e-02\n",
      "Epoch: [44][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 0.0871 (0.0871)\tMses 0.000 (0.000)\n",
      "Epoch: [44][5/6]\tTime 0.048 (0.045)\tData 0.000 (0.000)\tLoss 0.0775 (0.0819)\tMses 0.002 (0.001)\n",
      "Test: [0/2]\tTime 0.016 (0.016)\tLoss 0.0772 (0.0772)\tError0.004 (0.004)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-02\n",
      "Epoch: [45][0/6]\tTime 0.040 (0.040)\tData 0.000 (0.000)\tLoss 0.0734 (0.0734)\tMses 0.000 (0.000)\n",
      "Epoch: [45][5/6]\tTime 0.051 (0.043)\tData 0.000 (0.000)\tLoss 0.0676 (0.0745)\tMses 0.002 (0.006)\n",
      "Test: [0/2]\tTime 0.016 (0.016)\tLoss 0.0723 (0.0723)\tError0.006 (0.006)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-02\n",
      "Epoch: [46][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 0.0695 (0.0695)\tMses 0.003 (0.003)\n",
      "Epoch: [46][5/6]\tTime 0.041 (0.042)\tData 0.000 (0.000)\tLoss 0.0695 (0.0731)\tMses 0.006 (0.010)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0664 (0.0664)\tError0.002 (0.002)\n",
      " * Error 0.004\n",
      "current lr 1.00000e-02\n",
      "Epoch: [47][0/6]\tTime 0.043 (0.043)\tData 0.000 (0.000)\tLoss 0.0692 (0.0692)\tMses 0.005 (0.005)\n",
      "Epoch: [47][5/6]\tTime 0.041 (0.043)\tData 0.000 (0.000)\tLoss 0.0847 (0.0707)\tMses 0.028 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0749 (0.0749)\tError0.016 (0.016)\n",
      " * Error 0.013\n",
      "current lr 1.00000e-02\n",
      "Epoch: [48][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 0.0594 (0.0594)\tMses 0.001 (0.001)\n",
      "Epoch: [48][5/6]\tTime 0.045 (0.041)\tData 0.000 (0.000)\tLoss 0.0770 (0.0655)\tMses 0.025 (0.012)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0648 (0.0648)\tError0.011 (0.011)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-02\n",
      "Epoch: [49][0/6]\tTime 0.040 (0.040)\tData 0.000 (0.000)\tLoss 0.0553 (0.0553)\tMses 0.002 (0.002)\n",
      "Epoch: [49][5/6]\tTime 0.043 (0.043)\tData 0.000 (0.000)\tLoss 0.0556 (0.0644)\tMses 0.001 (0.012)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0621 (0.0621)\tError0.008 (0.008)\n",
      " * Error 0.010\n",
      "current lr 1.00000e-02\n",
      "Epoch: [50][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 0.0568 (0.0568)\tMses 0.002 (0.002)\n",
      "Epoch: [50][5/6]\tTime 0.041 (0.042)\tData 0.000 (0.000)\tLoss 0.0723 (0.0620)\tMses 0.023 (0.012)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0588 (0.0588)\tError0.008 (0.008)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-02\n",
      "Epoch: [51][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 0.0729 (0.0729)\tMses 0.022 (0.022)\n",
      "Epoch: [51][5/6]\tTime 0.044 (0.044)\tData 0.000 (0.000)\tLoss 0.0713 (0.0621)\tMses 0.021 (0.010)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0554 (0.0554)\tError0.005 (0.005)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-02\n",
      "Epoch: [52][0/6]\tTime 0.042 (0.042)\tData 0.000 (0.000)\tLoss 0.0540 (0.0540)\tMses 0.004 (0.004)\n",
      "Epoch: [52][5/6]\tTime 0.039 (0.047)\tData 0.000 (0.000)\tLoss 0.0567 (0.0555)\tMses 0.009 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0619 (0.0619)\tError0.015 (0.015)\n",
      " * Error 0.011\n",
      "current lr 1.00000e-02\n",
      "Epoch: [53][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0596 (0.0596)\tMses 0.013 (0.013)\n",
      "Epoch: [53][5/6]\tTime 0.041 (0.039)\tData 0.000 (0.000)\tLoss 0.0540 (0.0592)\tMses 0.001 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0512 (0.0512)\tError0.001 (0.001)\n",
      " * Error 0.001\n",
      "current lr 1.00000e-02\n",
      "Epoch: [54][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 0.0511 (0.0511)\tMses 0.000 (0.000)\n",
      "Epoch: [54][5/6]\tTime 0.039 (0.041)\tData 0.000 (0.000)\tLoss 0.0571 (0.0548)\tMses 0.014 (0.009)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0471 (0.0471)\tError0.003 (0.003)\n",
      " * Error 0.005\n",
      "current lr 1.00000e-02\n",
      "Epoch: [55][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0730 (0.0730)\tMses 0.029 (0.029)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [55][5/6]\tTime 0.042 (0.039)\tData 0.000 (0.000)\tLoss 0.0500 (0.0558)\tMses 0.002 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0527 (0.0527)\tError0.006 (0.006)\n",
      " * Error 0.010\n",
      "current lr 1.00000e-02\n",
      "Epoch: [56][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0648 (0.0648)\tMses 0.018 (0.018)\n",
      "Epoch: [56][5/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 0.0479 (0.0538)\tMses 0.000 (0.004)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0484 (0.0484)\tError0.003 (0.003)\n",
      " * Error 0.004\n",
      "current lr 1.00000e-02\n",
      "Epoch: [57][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 0.0481 (0.0481)\tMses 0.002 (0.002)\n",
      "Epoch: [57][5/6]\tTime 0.042 (0.042)\tData 0.000 (0.000)\tLoss 0.0594 (0.0507)\tMses 0.022 (0.010)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0469 (0.0469)\tError0.009 (0.009)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-02\n",
      "Epoch: [58][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0396 (0.0396)\tMses 0.001 (0.001)\n",
      "Epoch: [58][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0467 (0.0461)\tMses 0.010 (0.010)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0518 (0.0518)\tError0.014 (0.014)\n",
      " * Error 0.015\n",
      "current lr 1.00000e-02\n",
      "Epoch: [59][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0589 (0.0589)\tMses 0.021 (0.021)\n",
      "Epoch: [59][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0416 (0.0482)\tMses 0.000 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0496 (0.0496)\tError0.010 (0.010)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-02\n",
      "Epoch: [60][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0467 (0.0467)\tMses 0.007 (0.007)\n",
      "Epoch: [60][5/6]\tTime 0.043 (0.041)\tData 0.000 (0.000)\tLoss 0.0413 (0.0453)\tMses 0.002 (0.004)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0445 (0.0445)\tError0.006 (0.006)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-02\n",
      "Epoch: [61][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0721 (0.0721)\tMses 0.034 (0.034)\n",
      "Epoch: [61][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0431 (0.0479)\tMses 0.000 (0.006)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0487 (0.0487)\tError0.006 (0.006)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-02\n",
      "Epoch: [62][0/6]\tTime 0.042 (0.042)\tData 0.000 (0.000)\tLoss 0.0476 (0.0476)\tMses 0.005 (0.005)\n",
      "Epoch: [62][5/6]\tTime 0.043 (0.043)\tData 0.000 (0.000)\tLoss 0.0653 (0.0492)\tMses 0.028 (0.008)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0496 (0.0496)\tError0.012 (0.012)\n",
      " * Error 0.013\n",
      "current lr 1.00000e-02\n",
      "Epoch: [63][0/6]\tTime 0.039 (0.039)\tData 0.000 (0.000)\tLoss 0.0442 (0.0442)\tMses 0.007 (0.007)\n",
      "Epoch: [63][5/6]\tTime 0.042 (0.041)\tData 0.000 (0.000)\tLoss 0.0399 (0.0441)\tMses 0.000 (0.003)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0426 (0.0426)\tError0.005 (0.005)\n",
      " * Error 0.005\n",
      "current lr 1.00000e-02\n",
      "Epoch: [64][0/6]\tTime 0.039 (0.039)\tData 0.000 (0.000)\tLoss 0.0610 (0.0610)\tMses 0.024 (0.024)\n",
      "Epoch: [64][5/6]\tTime 0.043 (0.042)\tData 0.000 (0.000)\tLoss 0.0512 (0.0491)\tMses 0.009 (0.008)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0459 (0.0459)\tError0.005 (0.005)\n",
      " * Error 0.003\n",
      "current lr 1.00000e-02\n",
      "Epoch: [65][0/6]\tTime 0.040 (0.040)\tData 0.000 (0.000)\tLoss 0.0411 (0.0411)\tMses 0.000 (0.000)\n",
      "Epoch: [65][5/6]\tTime 0.048 (0.043)\tData 0.000 (0.000)\tLoss 0.0543 (0.0434)\tMses 0.023 (0.008)\n",
      "Test: [0/2]\tTime 0.016 (0.016)\tLoss 0.0565 (0.0565)\tError0.024 (0.024)\n",
      " * Error 0.019\n",
      "current lr 1.00000e-02\n",
      "Epoch: [66][0/6]\tTime 0.042 (0.042)\tData 0.000 (0.000)\tLoss 0.0577 (0.0577)\tMses 0.025 (0.025)\n",
      "Epoch: [66][5/6]\tTime 0.045 (0.046)\tData 0.000 (0.000)\tLoss 0.0468 (0.0439)\tMses 0.011 (0.009)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0401 (0.0401)\tError0.005 (0.005)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-02\n",
      "Epoch: [67][0/6]\tTime 0.043 (0.043)\tData 0.000 (0.000)\tLoss 0.0362 (0.0362)\tMses 0.001 (0.001)\n",
      "Epoch: [67][5/6]\tTime 0.047 (0.044)\tData 0.000 (0.000)\tLoss 0.0541 (0.0450)\tMses 0.020 (0.012)\n",
      "Test: [0/2]\tTime 0.016 (0.016)\tLoss 0.0415 (0.0415)\tError0.007 (0.007)\n",
      " * Error 0.010\n",
      "current lr 1.00000e-02\n",
      "Epoch: [68][0/6]\tTime 0.042 (0.042)\tData 0.000 (0.000)\tLoss 0.0552 (0.0552)\tMses 0.021 (0.021)\n",
      "Epoch: [68][5/6]\tTime 0.041 (0.044)\tData 0.000 (0.000)\tLoss 0.0875 (0.0505)\tMses 0.055 (0.015)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0571 (0.0571)\tError0.024 (0.024)\n",
      " * Error 0.018\n",
      "current lr 1.00000e-02\n",
      "Epoch: [69][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 0.0343 (0.0343)\tMses 0.001 (0.001)\n",
      "Epoch: [69][5/6]\tTime 0.046 (0.043)\tData 0.000 (0.000)\tLoss 0.0705 (0.0430)\tMses 0.040 (0.011)\n",
      "Test: [0/2]\tTime 0.016 (0.016)\tLoss 0.0339 (0.0339)\tError0.002 (0.002)\n",
      " * Error 0.001\n",
      "current lr 1.00000e-02\n",
      "Epoch: [70][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 0.0691 (0.0691)\tMses 0.037 (0.037)\n",
      "Epoch: [70][5/6]\tTime 0.045 (0.040)\tData 0.000 (0.000)\tLoss 0.0440 (0.0461)\tMses 0.008 (0.010)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0420 (0.0420)\tError0.006 (0.006)\n",
      " * Error 0.004\n",
      "current lr 1.00000e-02\n",
      "Epoch: [71][0/6]\tTime 0.041 (0.041)\tData 0.000 (0.000)\tLoss 0.0431 (0.0431)\tMses 0.007 (0.007)\n",
      "Epoch: [71][5/6]\tTime 0.039 (0.040)\tData 0.000 (0.000)\tLoss 0.0374 (0.0421)\tMses 0.002 (0.005)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0428 (0.0428)\tError0.008 (0.008)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-02\n",
      "Epoch: [72][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0389 (0.0389)\tMses 0.004 (0.004)\n",
      "Epoch: [72][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 0.0428 (0.0397)\tMses 0.010 (0.005)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0324 (0.0324)\tError0.000 (0.000)\n",
      " * Error 0.017\n",
      "current lr 1.00000e-02\n",
      "Epoch: [73][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 0.0419 (0.0419)\tMses 0.010 (0.010)\n",
      "Epoch: [73][5/6]\tTime 0.039 (0.040)\tData 0.000 (0.000)\tLoss 0.0855 (0.0476)\tMses 0.053 (0.014)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0448 (0.0448)\tError0.011 (0.011)\n",
      " * Error 0.010\n",
      "current lr 1.00000e-02\n",
      "Epoch: [74][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0370 (0.0370)\tMses 0.004 (0.004)\n",
      "Epoch: [74][5/6]\tTime 0.042 (0.039)\tData 0.000 (0.000)\tLoss 0.0685 (0.0442)\tMses 0.036 (0.011)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0481 (0.0481)\tError0.014 (0.014)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-02\n",
      "Epoch: [75][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0359 (0.0359)\tMses 0.002 (0.002)\n",
      "Epoch: [75][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0418 (0.0427)\tMses 0.007 (0.010)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0434 (0.0434)\tError0.008 (0.008)\n",
      " * Error 0.019\n",
      "current lr 1.00000e-02\n",
      "Epoch: [76][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0427 (0.0427)\tMses 0.007 (0.007)\n",
      "Epoch: [76][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0433 (0.0469)\tMses 0.006 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0427 (0.0427)\tError0.003 (0.003)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-02\n",
      "Epoch: [77][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0415 (0.0415)\tMses 0.002 (0.002)\n",
      "Epoch: [77][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0379 (0.0423)\tMses 0.002 (0.005)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0357 (0.0357)\tError0.001 (0.001)\n",
      " * Error 0.005\n",
      "current lr 1.00000e-02\n",
      "Epoch: [78][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0445 (0.0445)\tMses 0.010 (0.010)\n",
      "Epoch: [78][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0466 (0.0433)\tMses 0.014 (0.009)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0444 (0.0444)\tError0.011 (0.011)\n",
      " * Error 0.009\n",
      "current lr 1.00000e-02\n",
      "Epoch: [79][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0380 (0.0380)\tMses 0.004 (0.004)\n",
      "Epoch: [79][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0647 (0.0438)\tMses 0.033 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0422 (0.0422)\tError0.009 (0.009)\n",
      " * Error 0.016\n",
      "current lr 1.00000e-03\n",
      "Epoch: [80][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0694 (0.0694)\tMses 0.036 (0.036)\n",
      "Epoch: [80][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0359 (0.0422)\tMses 0.002 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0370 (0.0370)\tError0.003 (0.003)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-03\n",
      "Epoch: [81][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0469 (0.0469)\tMses 0.013 (0.013)\n",
      "Epoch: [81][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0505 (0.0460)\tMses 0.015 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0366 (0.0366)\tError0.002 (0.002)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-03\n",
      "Epoch: [82][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0359 (0.0359)\tMses 0.001 (0.001)\n",
      "Epoch: [82][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0681 (0.0423)\tMses 0.035 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0375 (0.0375)\tError0.004 (0.004)\n",
      " * Error 0.004\n",
      "current lr 1.00000e-03\n",
      "Epoch: [83][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0626 (0.0626)\tMses 0.029 (0.029)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [83][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0391 (0.0446)\tMses 0.005 (0.011)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0413 (0.0413)\tError0.007 (0.007)\n",
      " * Error 0.015\n",
      "current lr 1.00000e-03\n",
      "Epoch: [84][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0471 (0.0471)\tMses 0.013 (0.013)\n",
      "Epoch: [84][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0352 (0.0397)\tMses 0.001 (0.005)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0344 (0.0344)\tError0.000 (0.000)\n",
      " * Error 0.009\n",
      "current lr 1.00000e-03\n",
      "Epoch: [85][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 0.0376 (0.0376)\tMses 0.003 (0.003)\n",
      "Epoch: [85][5/6]\tTime 0.044 (0.042)\tData 0.000 (0.000)\tLoss 0.0337 (0.0387)\tMses 0.000 (0.005)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0376 (0.0376)\tError0.004 (0.004)\n",
      " * Error 0.010\n",
      "current lr 1.00000e-03\n",
      "Epoch: [86][0/6]\tTime 0.040 (0.040)\tData 0.000 (0.000)\tLoss 0.0346 (0.0346)\tMses 0.001 (0.001)\n",
      "Epoch: [86][5/6]\tTime 0.041 (0.039)\tData 0.000 (0.000)\tLoss 0.0387 (0.0421)\tMses 0.006 (0.009)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0447 (0.0447)\tError0.011 (0.011)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-03\n",
      "Epoch: [87][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0448 (0.0448)\tMses 0.012 (0.012)\n",
      "Epoch: [87][5/6]\tTime 0.042 (0.040)\tData 0.000 (0.000)\tLoss 0.0351 (0.0424)\tMses 0.002 (0.010)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0434 (0.0434)\tError0.011 (0.011)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-03\n",
      "Epoch: [88][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0425 (0.0425)\tMses 0.010 (0.010)\n",
      "Epoch: [88][5/6]\tTime 0.041 (0.039)\tData 0.000 (0.000)\tLoss 0.0403 (0.0425)\tMses 0.007 (0.009)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0342 (0.0342)\tError0.001 (0.001)\n",
      " * Error 0.003\n",
      "current lr 1.00000e-03\n",
      "Epoch: [89][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0358 (0.0358)\tMses 0.002 (0.002)\n",
      "Epoch: [89][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0401 (0.0379)\tMses 0.007 (0.005)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0388 (0.0388)\tError0.006 (0.006)\n",
      " * Error 0.005\n",
      "current lr 1.00000e-03\n",
      "Epoch: [90][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0423 (0.0423)\tMses 0.010 (0.010)\n",
      "Epoch: [90][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0946 (0.0478)\tMses 0.062 (0.015)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0476 (0.0476)\tError0.015 (0.015)\n",
      " * Error 0.009\n",
      "current lr 1.00000e-03\n",
      "Epoch: [91][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0386 (0.0386)\tMses 0.006 (0.006)\n",
      "Epoch: [91][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0385 (0.0401)\tMses 0.005 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0458 (0.0458)\tError0.013 (0.013)\n",
      " * Error 0.023\n",
      "current lr 1.00000e-03\n",
      "Epoch: [92][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0513 (0.0513)\tMses 0.018 (0.018)\n",
      "Epoch: [92][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0828 (0.0472)\tMses 0.050 (0.014)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0507 (0.0507)\tError0.017 (0.017)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-03\n",
      "Epoch: [93][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0344 (0.0344)\tMses 0.001 (0.001)\n",
      "Epoch: [93][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0414 (0.0396)\tMses 0.009 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0325 (0.0325)\tError0.000 (0.000)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-03\n",
      "Epoch: [94][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0482 (0.0482)\tMses 0.016 (0.016)\n",
      "Epoch: [94][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0369 (0.0394)\tMses 0.004 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0332 (0.0332)\tError0.000 (0.000)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-03\n",
      "Epoch: [95][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0334 (0.0334)\tMses 0.001 (0.001)\n",
      "Epoch: [95][5/6]\tTime 0.040 (0.043)\tData 0.000 (0.000)\tLoss 0.0475 (0.0392)\tMses 0.016 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0404 (0.0404)\tError0.009 (0.009)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-03\n",
      "Epoch: [96][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0504 (0.0504)\tMses 0.019 (0.019)\n",
      "Epoch: [96][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0475 (0.0509)\tMses 0.015 (0.019)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0448 (0.0448)\tError0.012 (0.012)\n",
      " * Error 0.010\n",
      "current lr 1.00000e-03\n",
      "Epoch: [97][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0502 (0.0502)\tMses 0.017 (0.017)\n",
      "Epoch: [97][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0482 (0.0419)\tMses 0.015 (0.009)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0457 (0.0457)\tError0.012 (0.012)\n",
      " * Error 0.009\n",
      "current lr 1.00000e-03\n",
      "Epoch: [98][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0440 (0.0440)\tMses 0.011 (0.011)\n",
      "Epoch: [98][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0426 (0.0383)\tMses 0.009 (0.005)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0366 (0.0366)\tError0.003 (0.003)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-03\n",
      "Epoch: [99][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0461 (0.0461)\tMses 0.013 (0.013)\n",
      "Epoch: [99][5/6]\tTime 0.042 (0.038)\tData 0.000 (0.000)\tLoss 0.0509 (0.0414)\tMses 0.018 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0358 (0.0358)\tError0.003 (0.003)\n",
      " * Error 0.003\n",
      "current lr 1.00000e-03\n",
      "Epoch: [100][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0506 (0.0506)\tMses 0.017 (0.017)\n",
      "Epoch: [100][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0347 (0.0419)\tMses 0.001 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0419 (0.0419)\tError0.008 (0.008)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-03\n",
      "Epoch: [101][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0466 (0.0466)\tMses 0.013 (0.013)\n",
      "Epoch: [101][5/6]\tTime 0.042 (0.039)\tData 0.000 (0.000)\tLoss 0.0376 (0.0489)\tMses 0.004 (0.015)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0474 (0.0474)\tError0.014 (0.014)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-03\n",
      "Epoch: [102][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0719 (0.0719)\tMses 0.039 (0.039)\n",
      "Epoch: [102][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0418 (0.0433)\tMses 0.008 (0.010)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0372 (0.0372)\tError0.003 (0.003)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-03\n",
      "Epoch: [103][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0352 (0.0352)\tMses 0.001 (0.001)\n",
      "Epoch: [103][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0568 (0.0396)\tMses 0.024 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0507 (0.0507)\tError0.018 (0.018)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-03\n",
      "Epoch: [104][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.1074 (0.1074)\tMses 0.075 (0.075)\n",
      "Epoch: [104][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0371 (0.0498)\tMses 0.004 (0.017)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0456 (0.0456)\tError0.012 (0.012)\n",
      " * Error 0.009\n",
      "current lr 1.00000e-03\n",
      "Epoch: [105][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0360 (0.0360)\tMses 0.002 (0.002)\n",
      "Epoch: [105][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0547 (0.0454)\tMses 0.021 (0.012)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0414 (0.0414)\tError0.008 (0.008)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-03\n",
      "Epoch: [106][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0391 (0.0391)\tMses 0.006 (0.006)\n",
      "Epoch: [106][5/6]\tTime 0.041 (0.039)\tData 0.000 (0.000)\tLoss 0.0432 (0.0445)\tMses 0.010 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0401 (0.0401)\tError0.006 (0.006)\n",
      " * Error 0.010\n",
      "current lr 1.00000e-03\n",
      "Epoch: [107][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0348 (0.0348)\tMses 0.001 (0.001)\n",
      "Epoch: [107][5/6]\tTime 0.041 (0.039)\tData 0.000 (0.000)\tLoss 0.0398 (0.0391)\tMses 0.007 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0475 (0.0475)\tError0.015 (0.015)\n",
      " * Error 0.019\n",
      "current lr 1.00000e-03\n",
      "Epoch: [108][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0468 (0.0468)\tMses 0.014 (0.014)\n",
      "Epoch: [108][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0422 (0.0423)\tMses 0.009 (0.009)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0352 (0.0352)\tError0.002 (0.002)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-03\n",
      "Epoch: [109][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0345 (0.0345)\tMses 0.001 (0.001)\n",
      "Epoch: [109][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0370 (0.0452)\tMses 0.004 (0.012)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0398 (0.0398)\tError0.006 (0.006)\n",
      " * Error 0.009\n",
      "current lr 1.00000e-03\n",
      "Epoch: [110][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0350 (0.0350)\tMses 0.002 (0.002)\n",
      "Epoch: [110][5/6]\tTime 0.041 (0.039)\tData 0.000 (0.000)\tLoss 0.0494 (0.0384)\tMses 0.017 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0487 (0.0487)\tError0.017 (0.017)\n",
      " * Error 0.013\n",
      "current lr 1.00000e-03\n",
      "Epoch: [111][0/6]\tTime 0.050 (0.050)\tData 0.000 (0.000)\tLoss 0.0375 (0.0375)\tMses 0.005 (0.005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [111][5/6]\tTime 0.039 (0.043)\tData 0.000 (0.000)\tLoss 0.0335 (0.0384)\tMses 0.001 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0337 (0.0337)\tError0.001 (0.001)\n",
      " * Error 0.004\n",
      "current lr 1.00000e-03\n",
      "Epoch: [112][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0429 (0.0429)\tMses 0.010 (0.010)\n",
      "Epoch: [112][5/6]\tTime 0.041 (0.039)\tData 0.000 (0.000)\tLoss 0.0427 (0.0396)\tMses 0.010 (0.007)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0433 (0.0433)\tError0.010 (0.010)\n",
      " * Error 0.005\n",
      "current lr 1.00000e-03\n",
      "Epoch: [113][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0361 (0.0361)\tMses 0.003 (0.003)\n",
      "Epoch: [113][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0428 (0.0375)\tMses 0.011 (0.005)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0438 (0.0438)\tError0.012 (0.012)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-03\n",
      "Epoch: [114][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0325 (0.0325)\tMses 0.000 (0.000)\n",
      "Epoch: [114][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0403 (0.0392)\tMses 0.008 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0351 (0.0351)\tError0.003 (0.003)\n",
      " * Error 0.003\n",
      "current lr 1.00000e-03\n",
      "Epoch: [115][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0395 (0.0395)\tMses 0.008 (0.008)\n",
      "Epoch: [115][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0352 (0.0430)\tMses 0.003 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0410 (0.0410)\tError0.008 (0.008)\n",
      " * Error 0.015\n",
      "current lr 1.00000e-03\n",
      "Epoch: [116][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0478 (0.0478)\tMses 0.015 (0.015)\n",
      "Epoch: [116][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0348 (0.0401)\tMses 0.001 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0478 (0.0478)\tError0.014 (0.014)\n",
      " * Error 0.016\n",
      "current lr 1.00000e-03\n",
      "Epoch: [117][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0655 (0.0655)\tMses 0.032 (0.032)\n",
      "Epoch: [117][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0353 (0.0463)\tMses 0.001 (0.012)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0373 (0.0373)\tError0.003 (0.003)\n",
      " * Error 0.009\n",
      "current lr 1.00000e-03\n",
      "Epoch: [118][0/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 0.0789 (0.0789)\tMses 0.045 (0.045)\n",
      "Epoch: [118][5/6]\tTime 0.039 (0.038)\tData 0.000 (0.000)\tLoss 0.0357 (0.0473)\tMses 0.001 (0.013)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0541 (0.0541)\tError0.019 (0.019)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-03\n",
      "Epoch: [119][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0436 (0.0436)\tMses 0.008 (0.008)\n",
      "Epoch: [119][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0503 (0.0471)\tMses 0.015 (0.012)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0387 (0.0387)\tError0.003 (0.003)\n",
      " * Error 0.010\n",
      "current lr 1.00000e-04\n",
      "Epoch: [120][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0446 (0.0446)\tMses 0.009 (0.009)\n",
      "Epoch: [120][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0451 (0.0422)\tMses 0.010 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0389 (0.0389)\tError0.004 (0.004)\n",
      " * Error 0.004\n",
      "current lr 1.00000e-04\n",
      "Epoch: [121][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0380 (0.0380)\tMses 0.003 (0.003)\n",
      "Epoch: [121][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0468 (0.0428)\tMses 0.011 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0400 (0.0400)\tError0.005 (0.005)\n",
      " * Error 0.004\n",
      "current lr 1.00000e-04\n",
      "Epoch: [122][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0353 (0.0353)\tMses 0.000 (0.000)\n",
      "Epoch: [122][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 0.0405 (0.0401)\tMses 0.005 (0.005)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0404 (0.0404)\tError0.005 (0.005)\n",
      " * Error 0.003\n",
      "current lr 1.00000e-04\n",
      "Epoch: [123][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0410 (0.0410)\tMses 0.006 (0.006)\n",
      "Epoch: [123][5/6]\tTime 0.039 (0.038)\tData 0.000 (0.000)\tLoss 0.0492 (0.0405)\tMses 0.014 (0.005)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0452 (0.0452)\tError0.010 (0.010)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-04\n",
      "Epoch: [124][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0389 (0.0389)\tMses 0.004 (0.004)\n",
      "Epoch: [124][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0352 (0.0412)\tMses 0.000 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0441 (0.0441)\tError0.009 (0.009)\n",
      " * Error 0.009\n",
      "current lr 1.00000e-04\n",
      "Epoch: [125][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0463 (0.0463)\tMses 0.011 (0.011)\n",
      "Epoch: [125][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0373 (0.0406)\tMses 0.002 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0430 (0.0430)\tError0.008 (0.008)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-04\n",
      "Epoch: [126][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0380 (0.0380)\tMses 0.003 (0.003)\n",
      "Epoch: [126][5/6]\tTime 0.038 (0.038)\tData 0.000 (0.000)\tLoss 0.0359 (0.0396)\tMses 0.001 (0.005)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0407 (0.0407)\tError0.006 (0.006)\n",
      " * Error 0.004\n",
      "current lr 1.00000e-04\n",
      "Epoch: [127][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0395 (0.0395)\tMses 0.005 (0.005)\n",
      "Epoch: [127][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0353 (0.0390)\tMses 0.001 (0.004)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0445 (0.0445)\tError0.010 (0.010)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-04\n",
      "Epoch: [128][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0445 (0.0445)\tMses 0.010 (0.010)\n",
      "Epoch: [128][5/6]\tTime 0.039 (0.038)\tData 0.000 (0.000)\tLoss 0.0379 (0.0391)\tMses 0.003 (0.005)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0513 (0.0513)\tError0.017 (0.017)\n",
      " * Error 0.010\n",
      "current lr 1.00000e-04\n",
      "Epoch: [129][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0598 (0.0598)\tMses 0.025 (0.025)\n",
      "Epoch: [129][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0398 (0.0416)\tMses 0.005 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0394 (0.0394)\tError0.005 (0.005)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-04\n",
      "Epoch: [130][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0381 (0.0381)\tMses 0.004 (0.004)\n",
      "Epoch: [130][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0345 (0.0362)\tMses 0.000 (0.002)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0351 (0.0351)\tError0.001 (0.001)\n",
      " * Error 0.005\n",
      "current lr 1.00000e-04\n",
      "Epoch: [131][0/6]\tTime 0.067 (0.067)\tData 0.000 (0.000)\tLoss 0.0412 (0.0412)\tMses 0.007 (0.007)\n",
      "Epoch: [131][5/6]\tTime 0.043 (0.044)\tData 0.000 (0.000)\tLoss 0.0419 (0.0454)\tMses 0.007 (0.011)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0461 (0.0461)\tError0.012 (0.012)\n",
      " * Error 0.013\n",
      "current lr 1.00000e-04\n",
      "Epoch: [132][0/6]\tTime 0.039 (0.039)\tData 0.000 (0.000)\tLoss 0.0423 (0.0423)\tMses 0.008 (0.008)\n",
      "Epoch: [132][5/6]\tTime 0.039 (0.039)\tData 0.000 (0.000)\tLoss 0.0429 (0.0431)\tMses 0.009 (0.009)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0534 (0.0534)\tError0.019 (0.019)\n",
      " * Error 0.011\n",
      "current lr 1.00000e-04\n",
      "Epoch: [133][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0356 (0.0356)\tMses 0.001 (0.001)\n",
      "Epoch: [133][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0459 (0.0402)\tMses 0.012 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0410 (0.0410)\tError0.007 (0.007)\n",
      " * Error 0.003\n",
      "current lr 1.00000e-04\n",
      "Epoch: [134][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0401 (0.0401)\tMses 0.006 (0.006)\n",
      "Epoch: [134][5/6]\tTime 0.040 (0.043)\tData 0.000 (0.000)\tLoss 0.0550 (0.0418)\tMses 0.021 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0396 (0.0396)\tError0.005 (0.005)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-04\n",
      "Epoch: [135][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0360 (0.0360)\tMses 0.002 (0.002)\n",
      "Epoch: [135][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 0.0349 (0.0383)\tMses 0.001 (0.004)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0417 (0.0417)\tError0.008 (0.008)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-04\n",
      "Epoch: [136][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0344 (0.0344)\tMses 0.000 (0.000)\n",
      "Epoch: [136][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0715 (0.0434)\tMses 0.038 (0.009)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0399 (0.0399)\tError0.006 (0.006)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-04\n",
      "Epoch: [137][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0373 (0.0373)\tMses 0.003 (0.003)\n",
      "Epoch: [137][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0361 (0.0397)\tMses 0.002 (0.006)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0396 (0.0396)\tError0.006 (0.006)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-04\n",
      "Epoch: [138][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0376 (0.0376)\tMses 0.004 (0.004)\n",
      "Epoch: [138][5/6]\tTime 0.041 (0.039)\tData 0.000 (0.000)\tLoss 0.0552 (0.0430)\tMses 0.021 (0.009)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0372 (0.0372)\tError0.004 (0.004)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-04\n",
      "Epoch: [139][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0441 (0.0441)\tMses 0.010 (0.010)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [139][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0394 (0.0477)\tMses 0.006 (0.014)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0404 (0.0404)\tError0.007 (0.007)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-04\n",
      "Epoch: [140][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0415 (0.0415)\tMses 0.008 (0.008)\n",
      "Epoch: [140][5/6]\tTime 0.041 (0.039)\tData 0.000 (0.000)\tLoss 0.0462 (0.0396)\tMses 0.012 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0479 (0.0479)\tError0.014 (0.014)\n",
      " * Error 0.018\n",
      "current lr 1.00000e-04\n",
      "Epoch: [141][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0347 (0.0347)\tMses 0.001 (0.001)\n",
      "Epoch: [141][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0368 (0.0389)\tMses 0.003 (0.005)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0468 (0.0468)\tError0.013 (0.013)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-04\n",
      "Epoch: [142][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0449 (0.0449)\tMses 0.011 (0.011)\n",
      "Epoch: [142][5/6]\tTime 0.039 (0.038)\tData 0.000 (0.000)\tLoss 0.0496 (0.0422)\tMses 0.016 (0.009)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0480 (0.0480)\tError0.014 (0.014)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-04\n",
      "Epoch: [143][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0415 (0.0415)\tMses 0.008 (0.008)\n",
      "Epoch: [143][5/6]\tTime 0.039 (0.038)\tData 0.000 (0.000)\tLoss 0.0341 (0.0397)\tMses 0.000 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0452 (0.0452)\tError0.012 (0.012)\n",
      " * Error 0.010\n",
      "current lr 1.00000e-04\n",
      "Epoch: [144][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0347 (0.0347)\tMses 0.001 (0.001)\n",
      "Epoch: [144][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0406 (0.0405)\tMses 0.007 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0365 (0.0365)\tError0.003 (0.003)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-04\n",
      "Epoch: [145][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0338 (0.0338)\tMses 0.000 (0.000)\n",
      "Epoch: [145][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0384 (0.0415)\tMses 0.005 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0365 (0.0365)\tError0.003 (0.003)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-04\n",
      "Epoch: [146][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0671 (0.0671)\tMses 0.034 (0.034)\n",
      "Epoch: [146][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0379 (0.0484)\tMses 0.004 (0.015)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0337 (0.0337)\tError0.000 (0.000)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-04\n",
      "Epoch: [147][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0351 (0.0351)\tMses 0.002 (0.002)\n",
      "Epoch: [147][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0449 (0.0408)\tMses 0.011 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0507 (0.0507)\tError0.017 (0.017)\n",
      " * Error 0.017\n",
      "current lr 1.00000e-04\n",
      "Epoch: [148][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0474 (0.0474)\tMses 0.014 (0.014)\n",
      "Epoch: [148][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 0.0470 (0.0416)\tMses 0.013 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0355 (0.0355)\tError0.002 (0.002)\n",
      " * Error 0.009\n",
      "current lr 1.00000e-04\n",
      "Epoch: [149][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0348 (0.0348)\tMses 0.001 (0.001)\n",
      "Epoch: [149][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0340 (0.0409)\tMses 0.000 (0.007)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0369 (0.0369)\tError0.003 (0.003)\n",
      " * Error 0.005\n",
      "current lr 1.00000e-04\n",
      "Epoch: [150][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0348 (0.0348)\tMses 0.001 (0.001)\n",
      "Epoch: [150][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0428 (0.0390)\tMses 0.009 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0382 (0.0382)\tError0.005 (0.005)\n",
      " * Error 0.005\n",
      "current lr 1.00000e-04\n",
      "Epoch: [151][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0393 (0.0393)\tMses 0.006 (0.006)\n",
      "Epoch: [151][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0503 (0.0382)\tMses 0.017 (0.005)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0431 (0.0431)\tError0.010 (0.010)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-04\n",
      "Epoch: [152][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0388 (0.0388)\tMses 0.006 (0.006)\n",
      "Epoch: [152][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0450 (0.0405)\tMses 0.012 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0339 (0.0339)\tError0.001 (0.001)\n",
      " * Error 0.000\n",
      "current lr 1.00000e-04\n",
      "Epoch: [153][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0415 (0.0415)\tMses 0.008 (0.008)\n",
      "Epoch: [153][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0347 (0.0392)\tMses 0.001 (0.006)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0335 (0.0335)\tError0.000 (0.000)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-04\n",
      "Epoch: [154][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0369 (0.0369)\tMses 0.004 (0.004)\n",
      "Epoch: [154][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 0.0348 (0.0390)\tMses 0.002 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0530 (0.0530)\tError0.020 (0.020)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-04\n",
      "Epoch: [155][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0345 (0.0345)\tMses 0.001 (0.001)\n",
      "Epoch: [155][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0412 (0.0397)\tMses 0.008 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0366 (0.0366)\tError0.003 (0.003)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-04\n",
      "Epoch: [156][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0367 (0.0367)\tMses 0.004 (0.004)\n",
      "Epoch: [156][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0434 (0.0400)\tMses 0.010 (0.007)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0380 (0.0380)\tError0.005 (0.005)\n",
      " * Error 0.011\n",
      "current lr 1.00000e-04\n",
      "Epoch: [157][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0355 (0.0355)\tMses 0.002 (0.002)\n",
      "Epoch: [157][5/6]\tTime 0.042 (0.039)\tData 0.000 (0.000)\tLoss 0.0444 (0.0414)\tMses 0.011 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0396 (0.0396)\tError0.007 (0.007)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-04\n",
      "Epoch: [158][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0431 (0.0431)\tMses 0.010 (0.010)\n",
      "Epoch: [158][5/6]\tTime 0.039 (0.038)\tData 0.000 (0.000)\tLoss 0.0334 (0.0390)\tMses 0.000 (0.006)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0432 (0.0432)\tError0.010 (0.010)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-04\n",
      "Epoch: [159][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0426 (0.0426)\tMses 0.010 (0.010)\n",
      "Epoch: [159][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0615 (0.0414)\tMses 0.028 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0601 (0.0601)\tError0.027 (0.027)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-05\n",
      "Epoch: [160][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0484 (0.0484)\tMses 0.015 (0.015)\n",
      "Epoch: [160][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0357 (0.0432)\tMses 0.003 (0.010)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0347 (0.0347)\tError0.002 (0.002)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-05\n",
      "Epoch: [161][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0393 (0.0393)\tMses 0.006 (0.006)\n",
      "Epoch: [161][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0355 (0.0382)\tMses 0.002 (0.005)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0416 (0.0416)\tError0.009 (0.009)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-05\n",
      "Epoch: [162][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0413 (0.0413)\tMses 0.008 (0.008)\n",
      "Epoch: [162][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0423 (0.0416)\tMses 0.009 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0441 (0.0441)\tError0.011 (0.011)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-05\n",
      "Epoch: [163][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0436 (0.0436)\tMses 0.010 (0.010)\n",
      "Epoch: [163][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0427 (0.0424)\tMses 0.010 (0.009)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0488 (0.0488)\tError0.016 (0.016)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-05\n",
      "Epoch: [164][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0340 (0.0340)\tMses 0.001 (0.001)\n",
      "Epoch: [164][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0336 (0.0416)\tMses 0.000 (0.009)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0403 (0.0403)\tError0.007 (0.007)\n",
      " * Error 0.011\n",
      "current lr 1.00000e-05\n",
      "Epoch: [165][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0349 (0.0349)\tMses 0.002 (0.002)\n",
      "Epoch: [165][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0368 (0.0389)\tMses 0.004 (0.006)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0495 (0.0495)\tError0.016 (0.016)\n",
      " * Error 0.019\n",
      "current lr 1.00000e-05\n",
      "Epoch: [166][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0353 (0.0353)\tMses 0.002 (0.002)\n",
      "Epoch: [166][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0332 (0.0443)\tMses 0.000 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0352 (0.0352)\tError0.002 (0.002)\n",
      " * Error 0.009\n",
      "current lr 1.00000e-05\n",
      "Epoch: [167][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0338 (0.0338)\tMses 0.001 (0.001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [167][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0334 (0.0388)\tMses 0.000 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0407 (0.0407)\tError0.008 (0.008)\n",
      " * Error 0.008\n",
      "current lr 1.00000e-05\n",
      "Epoch: [168][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0455 (0.0455)\tMses 0.012 (0.012)\n",
      "Epoch: [168][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0381 (0.0392)\tMses 0.005 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0415 (0.0415)\tError0.008 (0.008)\n",
      " * Error 0.013\n",
      "current lr 1.00000e-05\n",
      "Epoch: [169][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0352 (0.0352)\tMses 0.002 (0.002)\n",
      "Epoch: [169][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0337 (0.0391)\tMses 0.001 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0549 (0.0549)\tError0.022 (0.022)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-05\n",
      "Epoch: [170][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0357 (0.0357)\tMses 0.003 (0.003)\n",
      "Epoch: [170][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0342 (0.0471)\tMses 0.001 (0.014)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0346 (0.0346)\tError0.001 (0.001)\n",
      " * Error 0.021\n",
      "current lr 1.00000e-05\n",
      "Epoch: [171][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0359 (0.0359)\tMses 0.003 (0.003)\n",
      "Epoch: [171][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 0.0343 (0.0393)\tMses 0.001 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0417 (0.0417)\tError0.009 (0.009)\n",
      " * Error 0.013\n",
      "current lr 1.00000e-05\n",
      "Epoch: [172][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0504 (0.0504)\tMses 0.017 (0.017)\n",
      "Epoch: [172][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0533 (0.0417)\tMses 0.020 (0.009)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0348 (0.0348)\tError0.002 (0.002)\n",
      " * Error 0.009\n",
      "current lr 1.00000e-05\n",
      "Epoch: [173][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0405 (0.0405)\tMses 0.007 (0.007)\n",
      "Epoch: [173][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0407 (0.0417)\tMses 0.008 (0.009)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0400 (0.0400)\tError0.007 (0.007)\n",
      " * Error 0.006\n",
      "current lr 1.00000e-05\n",
      "Epoch: [174][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0402 (0.0402)\tMses 0.007 (0.007)\n",
      "Epoch: [174][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0346 (0.0438)\tMses 0.001 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0487 (0.0487)\tError0.016 (0.016)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-05\n",
      "Epoch: [175][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0365 (0.0365)\tMses 0.003 (0.003)\n",
      "Epoch: [175][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0483 (0.0443)\tMses 0.015 (0.011)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0501 (0.0501)\tError0.017 (0.017)\n",
      " * Error 0.014\n",
      "current lr 1.00000e-05\n",
      "Epoch: [176][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0331 (0.0331)\tMses 0.000 (0.000)\n",
      "Epoch: [176][5/6]\tTime 0.038 (0.043)\tData 0.000 (0.000)\tLoss 0.0378 (0.0393)\tMses 0.005 (0.006)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0487 (0.0487)\tError0.016 (0.016)\n",
      " * Error 0.012\n",
      "current lr 1.00000e-05\n",
      "Epoch: [177][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0341 (0.0341)\tMses 0.001 (0.001)\n",
      "Epoch: [177][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0338 (0.0445)\tMses 0.001 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0335 (0.0335)\tError0.000 (0.000)\n",
      " * Error 0.003\n",
      "current lr 1.00000e-05\n",
      "Epoch: [178][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0421 (0.0421)\tMses 0.009 (0.009)\n",
      "Epoch: [178][5/6]\tTime 0.039 (0.038)\tData 0.000 (0.000)\tLoss 0.0353 (0.0390)\tMses 0.002 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0471 (0.0471)\tError0.014 (0.014)\n",
      " * Error 0.007\n",
      "current lr 1.00000e-05\n",
      "Epoch: [179][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0369 (0.0369)\tMses 0.004 (0.004)\n",
      "Epoch: [179][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0349 (0.0413)\tMses 0.002 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0361 (0.0361)\tError0.003 (0.003)\n",
      " * Error 0.013\n",
      "current lr 5.00000e-06\n",
      "Epoch: [180][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0389 (0.0389)\tMses 0.006 (0.006)\n",
      "Epoch: [180][5/6]\tTime 0.039 (0.038)\tData 0.000 (0.000)\tLoss 0.0517 (0.0400)\tMses 0.019 (0.007)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0363 (0.0363)\tError0.003 (0.003)\n",
      " * Error 0.004\n",
      "current lr 5.00000e-06\n",
      "Epoch: [181][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0374 (0.0374)\tMses 0.004 (0.004)\n",
      "Epoch: [181][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 0.0352 (0.0407)\tMses 0.002 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0395 (0.0395)\tError0.006 (0.006)\n",
      " * Error 0.008\n",
      "current lr 5.00000e-06\n",
      "Epoch: [182][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0385 (0.0385)\tMses 0.005 (0.005)\n",
      "Epoch: [182][5/6]\tTime 0.039 (0.038)\tData 0.000 (0.000)\tLoss 0.0349 (0.0376)\tMses 0.002 (0.005)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0350 (0.0350)\tError0.002 (0.002)\n",
      " * Error 0.005\n",
      "current lr 5.00000e-06\n",
      "Epoch: [183][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0560 (0.0560)\tMses 0.023 (0.023)\n",
      "Epoch: [183][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0339 (0.0472)\tMses 0.001 (0.014)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0372 (0.0372)\tError0.004 (0.004)\n",
      " * Error 0.016\n",
      "current lr 5.00000e-06\n",
      "Epoch: [184][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0410 (0.0410)\tMses 0.008 (0.008)\n",
      "Epoch: [184][5/6]\tTime 0.039 (0.038)\tData 0.000 (0.000)\tLoss 0.0418 (0.0403)\tMses 0.009 (0.007)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0497 (0.0497)\tError0.017 (0.017)\n",
      " * Error 0.017\n",
      "current lr 5.00000e-06\n",
      "Epoch: [185][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0382 (0.0382)\tMses 0.005 (0.005)\n",
      "Epoch: [185][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0641 (0.0456)\tMses 0.031 (0.012)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0434 (0.0434)\tError0.010 (0.010)\n",
      " * Error 0.007\n",
      "current lr 5.00000e-06\n",
      "Epoch: [186][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0335 (0.0335)\tMses 0.000 (0.000)\n",
      "Epoch: [186][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0335 (0.0374)\tMses 0.000 (0.004)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0496 (0.0496)\tError0.017 (0.017)\n",
      " * Error 0.021\n",
      "current lr 5.00000e-06\n",
      "Epoch: [187][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0340 (0.0340)\tMses 0.001 (0.001)\n",
      "Epoch: [187][5/6]\tTime 0.041 (0.039)\tData 0.000 (0.000)\tLoss 0.0348 (0.0392)\tMses 0.002 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0376 (0.0376)\tError0.005 (0.005)\n",
      " * Error 0.010\n",
      "current lr 5.00000e-06\n",
      "Epoch: [188][0/6]\tTime 0.039 (0.039)\tData 0.000 (0.000)\tLoss 0.0493 (0.0493)\tMses 0.016 (0.016)\n",
      "Epoch: [188][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 0.0849 (0.0456)\tMses 0.052 (0.013)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0352 (0.0352)\tError0.002 (0.002)\n",
      " * Error 0.005\n",
      "current lr 5.00000e-06\n",
      "Epoch: [189][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0395 (0.0395)\tMses 0.006 (0.006)\n",
      "Epoch: [189][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0449 (0.0395)\tMses 0.012 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0332 (0.0332)\tError0.000 (0.000)\n",
      " * Error 0.001\n",
      "current lr 5.00000e-06\n",
      "Epoch: [190][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0383 (0.0383)\tMses 0.005 (0.005)\n",
      "Epoch: [190][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0391 (0.0411)\tMses 0.006 (0.008)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0422 (0.0422)\tError0.009 (0.009)\n",
      " * Error 0.006\n",
      "current lr 5.00000e-06\n",
      "Epoch: [191][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0342 (0.0342)\tMses 0.001 (0.001)\n",
      "Epoch: [191][5/6]\tTime 0.044 (0.041)\tData 0.000 (0.000)\tLoss 0.0451 (0.0500)\tMses 0.012 (0.017)\n",
      "Test: [0/2]\tTime 0.015 (0.015)\tLoss 0.0446 (0.0446)\tError0.012 (0.012)\n",
      " * Error 0.010\n",
      "current lr 5.00000e-06\n",
      "Epoch: [192][0/6]\tTime 0.053 (0.053)\tData 0.000 (0.000)\tLoss 0.0568 (0.0568)\tMses 0.024 (0.024)\n",
      "Epoch: [192][5/6]\tTime 0.039 (0.041)\tData 0.000 (0.000)\tLoss 0.0343 (0.0427)\tMses 0.001 (0.010)\n",
      "Test: [0/2]\tTime 0.013 (0.013)\tLoss 0.0441 (0.0441)\tError0.011 (0.011)\n",
      " * Error 0.015\n",
      "current lr 5.00000e-06\n",
      "Epoch: [193][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0389 (0.0389)\tMses 0.006 (0.006)\n",
      "Epoch: [193][5/6]\tTime 0.041 (0.039)\tData 0.000 (0.000)\tLoss 0.0612 (0.0466)\tMses 0.028 (0.014)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0375 (0.0375)\tError0.004 (0.004)\n",
      " * Error 0.004\n",
      "current lr 5.00000e-06\n",
      "Epoch: [194][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0335 (0.0335)\tMses 0.000 (0.000)\n",
      "Epoch: [194][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0725 (0.0437)\tMses 0.039 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0393 (0.0393)\tError0.006 (0.006)\n",
      " * Error 0.011\n",
      "current lr 5.00000e-06\n",
      "Epoch: [195][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0353 (0.0353)\tMses 0.002 (0.002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [195][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 0.0344 (0.0374)\tMses 0.001 (0.004)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0402 (0.0402)\tError0.007 (0.007)\n",
      " * Error 0.011\n",
      "current lr 5.00000e-06\n",
      "Epoch: [196][0/6]\tTime 0.037 (0.037)\tData 0.000 (0.000)\tLoss 0.0592 (0.0592)\tMses 0.026 (0.026)\n",
      "Epoch: [196][5/6]\tTime 0.041 (0.038)\tData 0.000 (0.000)\tLoss 0.0403 (0.0439)\tMses 0.007 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0418 (0.0418)\tError0.009 (0.009)\n",
      " * Error 0.007\n",
      "current lr 5.00000e-06\n",
      "Epoch: [197][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0345 (0.0345)\tMses 0.001 (0.001)\n",
      "Epoch: [197][5/6]\tTime 0.040 (0.039)\tData 0.000 (0.000)\tLoss 0.0364 (0.0437)\tMses 0.003 (0.011)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0382 (0.0382)\tError0.005 (0.005)\n",
      " * Error 0.007\n",
      "current lr 5.00000e-06\n",
      "Epoch: [198][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0440 (0.0440)\tMses 0.011 (0.011)\n",
      "Epoch: [198][5/6]\tTime 0.043 (0.039)\tData 0.000 (0.000)\tLoss 0.0356 (0.0387)\tMses 0.003 (0.006)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0533 (0.0533)\tError0.020 (0.020)\n",
      " * Error 0.014\n",
      "current lr 5.00000e-06\n",
      "Epoch: [199][0/6]\tTime 0.036 (0.036)\tData 0.000 (0.000)\tLoss 0.0427 (0.0427)\tMses 0.010 (0.010)\n",
      "Epoch: [199][5/6]\tTime 0.040 (0.038)\tData 0.000 (0.000)\tLoss 0.0349 (0.0462)\tMses 0.002 (0.013)\n",
      "Test: [0/2]\tTime 0.014 (0.014)\tLoss 0.0351 (0.0351)\tError0.002 (0.002)\n",
      " * Error 0.003\n"
     ]
    }
   ],
   "source": [
    "weight_1 = []\n",
    "weight_2 = []\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    x1 = np.random.normal(size=40)\n",
    "    x2 = np.random.normal(size=40)\n",
    "    X = np.stack((x1, x1), axis=-1)\n",
    "    y = x1+x1 + x1 #x1 + x2\n",
    "\n",
    "    X_train = X[0:30]\n",
    "    y_train = y[0:30]\n",
    "    X_test = X[30:40]\n",
    "    y_test = y[30:40]\n",
    "\n",
    "    train_dataset = Dataset(X_train, y_train)\n",
    "    val_dataset = Dataset(X_test, y_test)\n",
    "\n",
    "    #run model\n",
    "\n",
    "    args = arguments(200, 5, 5, 200, \"train\", 0.01, 0, \"test_model_no_noise\", \"model_checkpoints\")\n",
    "\n",
    "    model = Bay_TestNet(2, 3, 1)\n",
    "\n",
    "    criterion = nn.MSELoss().cpu()\n",
    "\n",
    "    run_custom_bnn(train_dataset,val_dataset,args,model,criterion)\n",
    "\n",
    "    inp = torch.tensor([[0.5, 0.5]], dtype=torch.float)\n",
    "\n",
    "    weight_1.append(model.l1.mu_weight.detach().numpy()[0][0])\n",
    "    weight_2.append(model.l1.mu_weight.detach().numpy()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.014919555"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(weight_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1012974"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(weight_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.full((1 ,2) ,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[15.0195, 15.0738]], requires_grad=True)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1.mu_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array([[0.,5,6],[0.,5,6]])\n",
    "var = np.array([[0.1,1,0.01],[0.01,0.01,0.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 5., 6.], dtype=torch.float64)"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000,\n",
       "        0.1000])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 0, -0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[0.],[20]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.Tensor(2, 3).detach()\n",
    "for row in range(l.shape[0]):\n",
    "    test[row] = torch.normal(mean=torch.from_numpy(l[row]), std=0.1, generator=None, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0183,  5.0091,  5.9324],\n",
       "        [-0.0260,  5.1976,  5.9561]])"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.1018,  2.5745,  3.1913,  3.9363,  4.8456,  5.6560,  6.9963,  8.2421,\n",
       "         8.9690, 10.2445])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1), generator=None, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1.mu_weight tensor([[0.6448, 0.5888]])\n",
      "l1.rho_weight tensor([[-2.8683, -3.1510]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.normal(size = 1500)\n",
    "x2 = np.random.normal(size = 1500)\n",
    "X = np.stack((x1,x2),axis = -1)\n",
    "y = x1 + x2  \n",
    "#+ np.random.normal(0,0.01,size = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:1000]\n",
    "y_train = y[0:1000]\n",
    "X_test = X[1000:1500]\n",
    "y_test = y[1000:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y, scale_data=False):\n",
    "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "            if scale_data:\n",
    "                X = StandardScaler().fit_transform(X)\n",
    "            self.X = torch.from_numpy(X).float()\n",
    "            self.y = torch.from_numpy(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "train_dataset = Dataset(X_train, y_train)\n",
    "test_dataset = Dataset(X_test,y_test)\n",
    "#trainloader = torch.utils.data.DataLoader(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sth still seems to be wrong with the error function or train method -> increased steadily\n",
    "#while training while val loss decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_file = args.save_dir + '/bayesian_{}.pth'.format(\n",
    "            args.model_name)\n",
    "checkpoint = torch.load(checkpoint_file)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_dataset = Dataset(np.array([[0.2,0.1]]),np.array([[0.3]]))\n",
    "ttest_loader = torch.utils.data.DataLoader(ttest_dataset,\n",
    "                                         batch_size=args.batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=args.workers,\n",
    "                                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_mc = []\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "output_list = []\n",
    "labels_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "        begin = time.time()\n",
    "        for data, target in ttest_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            else:\n",
    "                data, target = data.cpu(), target.cpu()\n",
    "            output_mc = []\n",
    "            for mc_run in range(1000):\n",
    "                output, _ = model.forward(data)\n",
    "                output_mc.append(output)\n",
    "            output_ = torch.stack(output_mc)\n",
    "            output_list.append(output_)\n",
    "        end = time.time()\n",
    "        output = torch.stack(output_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Bay_CPASNet(nn.Module):\n",
    "\tdef __init__(self, In_Nodes, Pathway_Nodes, Hidden_Nodes, Out_Nodes, Pathway_Mask):\n",
    "\t\tsuper(Bay_CPASNet, self).__init__()\n",
    "\t\tself.tanh = nn.Tanh()\n",
    "\t\tself.pathway_mask = Pathway_Mask\n",
    "\t\t###gene layer --> pathway layer\n",
    "\t\tself.sc1 = nn.Linear(In_Nodes, Pathway_Nodes)\n",
    "\t\t###pathway layer --> hidden layer\n",
    "\t\tself.sc2 = nn.Linear(Pathway_Nodes, Hidden_Nodes)\n",
    "\t\t###hidden layer --> hidden layer 2\n",
    "\t\tself.sc3 = nn.Linear(Hidden_Nodes, Out_Nodes, bias=False)\n",
    "\t\t###hidden layer 2 + age --> Cox layer\n",
    "\t\tself.sc4 = nn.Linear(Out_Nodes+1, 1, bias = False)\n",
    "\t\tself.sc4.weight.data.uniform_(-0.001, 0.001)\n",
    "\n",
    "\tdef forward(self, x_1, x_2):\n",
    "\t\t###force the connections between gene layer and pathway layer w.r.t. 'pathway_mask'\n",
    "\t\tself.sc1.weight.data = self.sc1.weight.data.mul(self.pathway_mask)\n",
    "\t\tx_1 = self.tanh(self.sc1(x_1))\n",
    "\t\tx_1 = self.tanh(self.sc2(x_1))\n",
    "\t\tx_1 = self.tanh(self.sc3(x_1))\n",
    "\t\t###combine age with hidden layer 2\n",
    "\t\tx_cat = torch.cat((x_1, x_2), 1)\n",
    "\t\tlin_pred = self.sc4(x_cat)\n",
    "\n",
    "\t\treturn lin_pred\n",
    "\n",
    "def trainBayCoxPASNet(train_x, train_age, train_ytime, train_yevent, \\\n",
    "\t\t\teval_x, eval_age, eval_ytime, eval_yevent, pathway_mask, \\\n",
    "\t\t\tIn_Nodes, Pathway_Nodes, Hidden_Nodes, Out_Nodes, \\\n",
    "\t\t\tLearning_Rate, Num_Epochs,bnn_prior_params):\n",
    "\n",
    "    net = Bay_CPASNet(In_Nodes, Pathway_Nodes, Hidden_Nodes, Out_Nodes, pathway_mask)\n",
    "    dnn_to_bnn_bcoxpas(net, bnn_prior_params)\n",
    "    \n",
    "    ###\n",
    "    ###optimizer\n",
    "    opt = optim.Adam(net.parameters(), lr=Learning_Rate)\n",
    "\n",
    "    for epoch in range(Num_Epochs+1):\n",
    "        net.train()\n",
    "        opt.zero_grad() ###reset gradients to zeros\n",
    "\n",
    "        pred = net(train_x, train_age) ###Forward\n",
    "        ce_loss = neg_par_log_likelihood(pred, train_ytime, train_yevent)\n",
    "        kl = get_kl_loss(net)\n",
    "        loss = ce_loss + kl\n",
    "        loss.backward() ###calculate gradients\n",
    "        opt.step()\n",
    "        net.sc1.weight.data = net.sc1.weight.data.mul(net.pathway_mask) ###force the connections between gene layer and pathway layer\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            with torch.no_grad():\n",
    "                net.train()\n",
    "                train_output_mc = []\n",
    "                for mc_run in range(10):\n",
    "                    output = net(train_x, train_age)\n",
    "                    train_output_mc.append(output)\n",
    "                    outputs = torch.stack(train_output_mc)\n",
    "                train_pred = outputs.mean(dim=0)\n",
    "                train_loss = neg_par_log_likelihood(train_pred, train_ytime, train_yevent).view(1,)\n",
    "\n",
    "                eval_output_mc = []\n",
    "                for mc_run in range(10):\n",
    "                    output = net(eval_x, eval_age)\n",
    "                    eval_output_mc.append(output)\n",
    "                    eval_outputs = torch.stack(eval_output_mc)\n",
    "                eval_pred = eval_outputs.mean(dim=0)\n",
    "                eval_loss = neg_par_log_likelihood(eval_pred, eval_ytime, eval_yevent).view(1,)\n",
    "\n",
    "                train_cindex = c_index(train_pred, train_ytime, train_yevent)\n",
    "                eval_cindex = c_index(eval_pred, eval_ytime, eval_yevent)\n",
    "                print(f\"Epoch: {epoch}, Train Loss: {train_loss},Eval Loss: {eval_loss}, \"\n",
    "                      f\" Train Cindex: {train_cindex}, Eval Cindex: {eval_cindex}\")\n",
    "\n",
    "    return (train_loss, eval_loss, train_cindex, eval_cindex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
